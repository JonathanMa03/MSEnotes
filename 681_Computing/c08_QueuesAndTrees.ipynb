{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Priority Queues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Trees\n",
    "\n",
    "Binary trees are important in many applications, some of which we will explore.\n",
    "\n",
    "A binary tree consists of a unique root node and optional additional nodes with the property that\n",
    "\n",
    "- every node has at most two child nodes L and R.\n",
    "- every non-root node as a unique parent node\n",
    "- every node has the root node as an ancestor (parent of a parent of a parent ...)\n",
    "- every node has some optional additional data associated with it contained in a dictionary. E.g. one item in the dictionary could be that node's depth (number of parent nodes in the path to the root node).\n",
    "\n",
    "A  **complete binary tree** is one in which, if $D$ is the largest depth of a node, then\n",
    "- for all depths $d=0,\\ldots,D-1$ the number of nodes is $2^{d}$,\n",
    "- at depth $D$ the nodes are as far to the left as possible.\n",
    "\n",
    "A complete binary tree can be implemented as a list with the following properties:\n",
    "\n",
    "- the root node appears in index 0\n",
    "- the children of node appearing in index i are at indexes\n",
    "    - 2i+1\n",
    "    - 2i+2\n",
    "\n",
    "As a result, the parent of a node appearing in index i appears in index (i-1)//2 (here the // means the integer part obtained when i-1 is divided by 2.\n",
    "\n",
    "Index Tree EX: \n",
    "\n",
    "0\n",
    "\n",
    "1 2\n",
    "\n",
    "3 4 5 6\n",
    "\n",
    "# Priority Queues and Heaps\n",
    "\n",
    "A priority queue is a data structure where we store items that can be ordered by priority. Priority of an iterm is determined by a numerical value with the smaller value receiving highter priority (sorry but that is the standard way of defining priority - maybe best to think of position of objects in a line numbered 0,1,... so the the 0th position gets higher priority). The data structure supports the following actions:\n",
    "\n",
    "- insert - adding a new pair (object, priority) to the queue\n",
    "- pop - returning the element from the queue with highest priority (lowest i-value) and removing it from the queue\n",
    "- peek - inspecting the highest priority item without removing it\n",
    "- determining the number of elements left in the queue without making any changes\n",
    "\n",
    "We want these operations to be efficient and it turns out that a priority queue can be efficiently implemented using a heap, which is a *complete binary tree structure* as described above with items stored at the nodes. Importantly, \n",
    "\n",
    "- the binary tree has the *heap property*: a parent is always at least as high priority as its children, and\n",
    "- the operations described above can be carried out efficiently.\n",
    "    - insertion - to insert an element, we add a node at the deepest depth and to the right of any existing nodes at that depth, or add a new depth and place the node at the leftmost position at that depth, then repeatedly swap its position with a parent whose priority is lower until its parent has higher priority (this is called bubbling up)\n",
    "    - pop - return the first element of the list and then replace it by the last element, then repeatedly swap this element with a child if one of them has higher priority until it has at least as high priority as its children.\n",
    "\n",
    "A heap will be *balanced*, meaning that the distance between a *leaf* (a node with no children) and the root node having one of two possible values.  \n",
    "\n",
    "\n",
    "**Efficiency of the heap** The operations above will each take at most $C\\log2(n)$ operations where $n$ is the number of objects stored and $C$ is a constant representing the cost of a pair of comparisons and swapping of two list elements.\n",
    "\n",
    "- Let i = index of newly inserted element.\n",
    "- Let p = floor[(i - 1) / 2.]\n",
    "- While i > 0 and value[i] < value[p]: swap their position and repeat\n",
    "\n",
    "High Priority = smaller value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heapify(L1, L2):\n",
    "    \"\"\"\n",
    "    Simulate min-heap insertion with step-by-step bubble-up prints.\n",
    "    L1: starting heap (list)\n",
    "    L2: values to insert\n",
    "    \"\"\"\n",
    "    heap = L1[:]  # copy\n",
    "\n",
    "    for v in L2:\n",
    "\n",
    "        print(f\"Initial list: {heap}\")\n",
    "\n",
    "        # Append new value to the list, find i and p\n",
    "        heap.append(v)\n",
    "        i = len(heap) - 1\n",
    "        p = (i - 1) // 2 if i > 0 else None\n",
    "\n",
    "        print(f\"New point {v}, List {heap}\")\n",
    "\n",
    "        # Root Case\n",
    "        if i == 0:\n",
    "            print(f\"Updated list: {heap}\\n\")\n",
    "            print(\"COMPLETE\\n\")\n",
    "            continue\n",
    "\n",
    "        # Bubble-up\n",
    "        while i > 0:\n",
    "            p = (i - 1) // 2\n",
    "\n",
    "            if heap[i] < heap[p]:\n",
    "                print(f\"Swap since heap[i={i}]={heap[i]} < heap[p={p}]={heap[p]}\")\n",
    "                heap[i], heap[p] = heap[p], heap[i]\n",
    "                print(f\"Updated list: {heap}\\n\")\n",
    "                i = p\n",
    "            else:\n",
    "                print(f\"No swap since heap[i={i}]={heap[i]} >= heap[p={p}]={heap[p]}\")\n",
    "                print(f\"Updated list: {heap}\\n\")\n",
    "                break\n",
    "\n",
    "        print(\"COMPLETE\\n\")\n",
    "\n",
    "    return heap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial list: [30, 50]\n",
      "New point 65, List [30, 50, 65]\n",
      "No swap since heap[i=2]=65 >= heap[p=0]=30\n",
      "Updated list: [30, 50, 65]\n",
      "\n",
      "COMPLETE\n",
      "\n",
      "Initial list: [30, 50, 65]\n",
      "New point 90, List [30, 50, 65, 90]\n",
      "No swap since heap[i=3]=90 >= heap[p=1]=50\n",
      "Updated list: [30, 50, 65, 90]\n",
      "\n",
      "COMPLETE\n",
      "\n",
      "Initial list: [30, 50, 65, 90]\n",
      "New point 45, List [30, 50, 65, 90, 45]\n",
      "Swap since heap[i=4]=45 < heap[p=1]=50\n",
      "Updated list: [30, 45, 65, 90, 50]\n",
      "\n",
      "No swap since heap[i=1]=45 >= heap[p=0]=30\n",
      "Updated list: [30, 45, 65, 90, 50]\n",
      "\n",
      "COMPLETE\n",
      "\n",
      "Initial list: [30, 45, 65, 90, 50]\n",
      "New point 20, List [30, 45, 65, 90, 50, 20]\n",
      "Swap since heap[i=5]=20 < heap[p=2]=65\n",
      "Updated list: [30, 45, 20, 90, 50, 65]\n",
      "\n",
      "Swap since heap[i=2]=20 < heap[p=0]=30\n",
      "Updated list: [20, 45, 30, 90, 50, 65]\n",
      "\n",
      "COMPLETE\n",
      "\n",
      "Final heap: [20, 45, 30, 90, 50, 65]\n"
     ]
    }
   ],
   "source": [
    "# Example usage matching your exercise:\n",
    "start = [30, 50]\n",
    "to_add = [65, 90, 45, 20]\n",
    "\n",
    "final_heap = heapify(start, to_add)\n",
    "print(\"Final heap:\", final_heap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.2176579634064998\n",
      "    0.546924252949452\n",
      "       0.6690101981140354\n",
      "          0.780267234719173\n",
      "          0.8768859478469114\n",
      "       0.8248801070984133\n",
      "    0.4336795828421094\n",
      "       0.4394591084063991\n",
      "       0.5317478696078605\n"
     ]
    }
   ],
   "source": [
    "# print a node and its children\n",
    "def print_node_and_children_of_node(L,i):\n",
    "    depth=3*int(np.log2(i+1))\n",
    "    indent_string=\"\".join([\" \" for j in range(depth+1)])\n",
    "    print(indent_string+str(L[i]))\n",
    "    child1=2*i+1\n",
    "    child2=2*i+2\n",
    "    if child1<len(L):\n",
    "        print_node_and_children_of_node(L,child1)\n",
    "    if child2<len(L):\n",
    "        print_node_and_children_of_node(L,child2)\n",
    "\n",
    "print_node_and_children_of_node(heap,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4336795828421094\n",
      "\n",
      "\n",
      " 0.4394591084063991\n",
      "    0.546924252949452\n",
      "       0.6690101981140354\n",
      "       0.8248801070984133\n",
      "    0.5317478696078605\n",
      "       0.8768859478469114\n",
      "       0.780267234719173\n"
     ]
    }
   ],
   "source": [
    "# popping\n",
    "x=heapq.heappop(heap)\n",
    "print(x)\n",
    "print(\"\\n\")\n",
    "print_node_and_children_of_node(heap,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.004687511326559424\n",
      "    0.19695598382606339\n",
      "       0.6573269655123397\n",
      "          0.8552142152616831\n",
      "          0.8194034024015693\n",
      "       0.43903171435909416\n",
      "          0.6569969372589074\n",
      "          0.4718516602872821\n",
      "    0.07846521725964206\n",
      "       0.165570536114101\n",
      "          0.9041898630952048\n",
      "          0.24188050631121905\n",
      "       0.08480032800808501\n",
      "          0.7549254836987843\n",
      "          0.668683692750721\n"
     ]
    }
   ],
   "source": [
    "# making a class to hide details from the user\n",
    "import heapq\n",
    "class PriorityQueue:\n",
    "    def __init__(self):\n",
    "        self._heap = []\n",
    "    \n",
    "    def push(self, item):\n",
    "        heapq.heappush(self._heap, item)\n",
    "    \n",
    "    def pop(self):\n",
    "        return heapq.heappop(self._heap)\n",
    "    \n",
    "    def peek(self):\n",
    "        return self._heap[0] if self._heap else None\n",
    "    \n",
    "    def print_node_and_children_of_node(self,i):\n",
    "        depth=3*int(np.log2(i+1))\n",
    "        indent_string=\"\".join([\" \" for j in range(depth+1)])\n",
    "        print(indent_string+str(self._heap[i]))\n",
    "        child1=2*i+1\n",
    "        child2=2*i+2\n",
    "        if child1<len(self._heap):\n",
    "            self.print_node_and_children_of_node(child1)\n",
    "        if child2<len(self._heap):\n",
    "            self.print_node_and_children_of_node(child2)\n",
    "\n",
    "import numpy as np\n",
    "PQ=PriorityQueue()\n",
    "for i in range(15):\n",
    "    u=np.random.uniform(0,1)\n",
    "    PQ.push(u)\n",
    "\n",
    "PQ.print_node_and_children_of_node(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Some small modifications**\n",
    "\n",
    "- Make pop and peek return None if the queue is empty\n",
    "- Add an is_empty() method\n",
    "- Add a __len__() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "class PriorityQueue:\n",
    "    def __init__(self):\n",
    "        self._heap = []\n",
    "    \n",
    "    def push(self, item):\n",
    "        heapq.heappush(self._heap, item)\n",
    "    \n",
    "    def pop(self):\n",
    "        if len(self._heap)==0:\n",
    "            return(None)\n",
    "        item=heapq.heappop(self._heap)\n",
    "        return(item)\n",
    "  \n",
    "    def peek(self):\n",
    "        if len(self._heap)==0:\n",
    "            return(None)\n",
    "        item=self._heap[0][1]\n",
    "        return item\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self._heap)\n",
    "\n",
    "    def is_empty(self):\n",
    "        if len(self._heap)==0:\n",
    "            return(True)\n",
    "        return(False)\n",
    "    def print_node_and_children_of_node(self,i):\n",
    "        depth=3*int(np.log2(i+1))\n",
    "        indent_string=\"\".join([\" \" for j in range(depth+1)])\n",
    "        print(indent_string+str(self._heap[i]))\n",
    "        child1=2*i+1\n",
    "        child2=2*i+2\n",
    "        if child1<len(self._heap):\n",
    "            self.print_node_and_children_of_node(child1)\n",
    "        if child2<len(self._heap):\n",
    "            self.print_node_and_children_of_node(child2)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004792444074259605\n",
      "0.04360711584097343\n",
      "0.0576247539197795\n",
      "0.06350533882847453\n",
      "0.08903014763959849\n",
      "0.10152283156790409\n",
      "0.13064838501306253\n",
      "0.14101361852313077\n",
      "0.1607888251196281\n",
      "0.21996653307709224\n",
      "0.2519961070287391\n",
      "0.2981839779846721\n",
      "0.30463845084109065\n",
      "0.36337691501980096\n",
      "0.5225950745413018\n",
      "0.6883893346966522\n",
      "0.699642387763238\n",
      "0.7025701559366495\n",
      "0.7075429373408348\n",
      "0.7972446125880351\n",
      "0.8114348376368729\n",
      "0.8436178392504993\n",
      "0.8781582355593823\n",
      "0.9616941728925474\n",
      "0.9987899607436168\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "PQ=PriorityQueue()\n",
    "for i in range(25):\n",
    "    p=np.random.uniform(0,1)\n",
    "    PQ.push(p) \n",
    "while not PQ.is_empty():\n",
    "    x=PQ.pop()\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Customized ordering**\n",
    "\n",
    "\n",
    "What if we want to put objects in a priority queue that are not immediately comparable?\n",
    "\n",
    "**Example.**\n",
    "\n",
    "In the following example, we consider a class of objects, each with a list as an attributes and where we use the sum of entres in the list to determine priority - a greater sum leading to higher priorty.\n",
    "\n",
    "**Notes**\n",
    "\n",
    "- We provide a \\_\\_lt\\_\\_() method for comparing two class instances\n",
    "- We pass the item as both arguments to the push method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding to the queue:\n",
      "   sum =  1.415 L = [0.726, 0.677, 0.012]\n",
      "   sum =  4.684 L = [0.779, 0.465, 0.685, 0.956, 0.083, 0.808, 0.79, 0.118]\n",
      "   sum =  2.812 L = [0.48, 0.03, 0.352, 0.322, 0.006, 0.671, 0.951]\n",
      "   sum =  1.628 L = [0.471, 0.787, 0.37]\n",
      "   sum =  2.457 L = [0.499, 0.405, 0.594, 0.009, 0.464, 0.486]\n",
      "   sum =  2.808 L = [0.418, 0.394, 0.61, 0.424, 0.962]\n",
      "   sum =  1.073 L = [0.985, 0.088] \n",
      "   sum =  4.596 L = [0.539, 0.406, 0.657, 0.654, 0.712, 0.582, 0.309, 0.737]\n",
      "   sum =  3.218 L = [0.869, 0.965, 0.454, 0.298, 0.632]\n",
      "   sum =  2.082 L = [0.725, 0.703, 0.564, 0.09]\n",
      "Number of things in the queue = 10\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create a class of things to put in the queue.\n",
    "class thing:\n",
    "    def __init__(self,L):\n",
    "        self.L=L\n",
    "    \n",
    "    def __lt__(self,other):\n",
    "        if sum(self.L)>=sum(other.L):\n",
    "            return(True)\n",
    "        return(False)  \n",
    "    def __str__(self):\n",
    "        st=\"[\"\n",
    "        for x in self.L:\n",
    "            st+=str(x)+\",\"\n",
    "        st+=\"]\"\n",
    "        st+=\" \"+str(sum(self.\n",
    "                        \n",
    "                        L))\n",
    "        return(st)\n",
    "\n",
    "# Create an instance of a priority queue\n",
    "PQ=PriorityQueue()\n",
    "\n",
    "# Add some things to the queue \n",
    "print(\"Adding to the queue:\")\n",
    "for i in range(10):\n",
    "    n=np.random.poisson(5)\n",
    "    L=[round(np.random.uniform(0,1),3) for j in range(n)]\n",
    "    t=thing(L)\n",
    "    PQ.push(t)\n",
    "    print(\"   sum = {0:6.3f} L = {1:15s}\".format(sum(L),str(L)))\n",
    "print(\"Number of things in the queue = \" + str(len(PQ)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [0.779,0.465,0.685,0.956,0.083,0.808,0.79,0.118,] 4.684\n",
      "    [0.539,0.406,0.657,0.654,0.712,0.582,0.309,0.737,] 4.596\n",
      "       [0.869,0.965,0.454,0.298,0.632,] 3.218\n",
      "          [0.726,0.677,0.012,] 1.415\n",
      "          [0.499,0.405,0.594,0.009,0.464,0.486,] 2.457\n",
      "       [0.725,0.703,0.564,0.09,] 2.082\n",
      "          [0.471,0.787,0.37,] 1.6280000000000001\n",
      "    [0.48,0.03,0.352,0.322,0.006,0.671,0.951,] 2.812\n",
      "       [0.418,0.394,0.61,0.424,0.962,] 2.808\n",
      "       [0.985,0.088,] 1.073\n"
     ]
    }
   ],
   "source": [
    "PQ.print_node_and_children_of_node(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now pop them all until the queue is empty**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sum =  4.684 L = [0.779, 0.465, 0.685, 0.956, 0.083, 0.808, 0.79, 0.118]\n",
      "   sum =  4.596 L = [0.539, 0.406, 0.657, 0.654, 0.712, 0.582, 0.309, 0.737]\n",
      "   sum =  3.218 L = [0.869, 0.965, 0.454, 0.298, 0.632]\n",
      "   sum =  2.812 L = [0.48, 0.03, 0.352, 0.322, 0.006, 0.671, 0.951]\n",
      "   sum =  2.808 L = [0.418, 0.394, 0.61, 0.424, 0.962]\n",
      "   sum =  2.457 L = [0.499, 0.405, 0.594, 0.009, 0.464, 0.486]\n",
      "   sum =  2.082 L = [0.725, 0.703, 0.564, 0.09]\n",
      "   sum =  1.628 L = [0.471, 0.787, 0.37]\n",
      "   sum =  1.415 L = [0.726, 0.677, 0.012]\n",
      "   sum =  1.073 L = [0.985, 0.088] \n"
     ]
    }
   ],
   "source": [
    "while not PQ.is_empty():\n",
    "    x=PQ.pop()\n",
    "    print(\"   sum = {0:6.3f} L = {1:15s}\".format(sum(x.L),str(x.L)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binary Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Binary Trees**\n",
    "\n",
    "To illustrate an application involving classes, we introduce binary trees. These will be important for building _decision trees_, which are important for classification. \n",
    "\n",
    "To build a binary tree, we start by creating a node class. An instance of a node has the following:\n",
    "\n",
    "- parent - a node if this node is not a root node and None if this is a root node\n",
    "- right child node\n",
    "- left child node\n",
    "- data associated with the node \n",
    "\n",
    "We want node methods to provide the following capabilities.\n",
    "\n",
    "- Create a root (parentless) node and add optional data to it.\n",
    "- Create a node with some parent and add optional data to it.\n",
    "- Retrieve the data associated with a node\n",
    "- Assign data to a node\n",
    "- Get the left child associated with a node if there is one\n",
    "- Get the right child associated with a node if there is one\n",
    "- Spawn a left child of a given node\n",
    "- Spawn a right child of a given node\n",
    "\n",
    "The data we associate with a node can be quite general. We'll use a dictionary at each node and in the code below, we'll store the depth of each node (depth is 0 for the root node, 1 for its children, 2 for its grandchildren etc.) and a label for each node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node label = 0:mother of all nodes\n",
      "   no parent i.e. root node\n",
      "   no left child\n",
      "   no right child\n",
      "\n",
      "node label = 1:daughter of mom of all nodes\n",
      "   parent label = 0:mother of all nodes\n",
      "   no left child\n",
      "   no right child\n",
      "\n",
      "node label = 1:son of mom of all nodes\n",
      "   parent label = 0:mother of all nodes\n",
      "   no left child\n",
      "   no right child\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class node:\n",
    "    __slots__=('parent','left_child','right_child','data')\n",
    "\n",
    "    def __init__(self,parent,data={}):\n",
    "        if parent==None:\n",
    "            # making this a root node\n",
    "            self.data=data\n",
    "            self.data[\"depth\"]=0\n",
    "            self.parent=None\n",
    "        else:\n",
    "            # making this a non-root node\n",
    "            self.data=data\n",
    "            self.data[\"depth\"]=parent.data[\"depth\"]+1\n",
    "            self.parent=parent\n",
    "        self.left_child=None\n",
    "        self.right_child=None\n",
    "    def spawn_left_child(self,data={}):\n",
    "        # create a new node n with self as parent w/ given data\n",
    "        n=node(parent=self,data=data)\n",
    "        #n.data=data\n",
    "        n.data[\"depth\"]=self.data[\"depth\"]+1\n",
    "        self.left_child=n\n",
    "        return(n)\n",
    "    def spawn_right_child(self,data={}):\n",
    "        n=node(parent=self,data=data)\n",
    "        #n.data=data\n",
    "        n.data[\"depth\"]=self.data[\"depth\"]+1\n",
    "        self.right_child=n\n",
    "        return(n)\n",
    "    \n",
    "    # string consisting of information about node\n",
    "    def __str__(self):\n",
    "        s=\"node label = \"+self.data[\"label\"]+\"\\n\"\n",
    "        if self.parent==None:\n",
    "            s+=\"   no parent i.e. root node\\n\"\n",
    "        else:\n",
    "            s+=\"   parent label = \" + self.parent.data[\"label\"]+\"\\n\"\n",
    "        if self.left_child==None:\n",
    "            s+=\"   no left child\\n\"\n",
    "        else:\n",
    "            s+=\"   left child label \" + self.left_child.data[\"label\"]+\"\\n\"\n",
    "        if self.right_child==None:\n",
    "            s+=\"   no right child\\n\"\n",
    "        else:\n",
    "            s+=\"   right child label \" + self.right_child.data[\"label\"]+\"\\n\"\n",
    "        \n",
    "        return(s)\n",
    "    \n",
    "    \n",
    "    \n",
    "rootnode=node(parent=None,data={\"label\":\"0:mother of all nodes\"})\n",
    "#print(\"parent of root node = \"+str(rootnode.parent))\n",
    "print(rootnode)\n",
    "\n",
    "node1=rootnode.spawn_left_child(data={\"label\":\"1:daughter of mom of all nodes\"})\n",
    "node2=rootnode.spawn_right_child(data={\"label\":\"1:son of mom of all nodes\"})\n",
    "print(node1)\n",
    "print(node2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node label = 0:mother of all nodes\n",
      "   no parent i.e. root node\n",
      "   left child label 1:daughter of mom of all nodes\n",
      "   right child label 1:son of mom of all nodes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(rootnode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build a tree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootnode=node(parent=None,data={\"label\":\"TD = Top dog\"})\n",
    "node1=rootnode.spawn_left_child(data={\"label\":\"DTD = daughter of Top Dog\"})\n",
    "node2=rootnode.spawn_right_child(data={\"label\":\"STD = son of Top Dog\"})\n",
    "node11=node1.spawn_left_child(data={\"label\":\"DDTD\"})\n",
    "node12=node1.spawn_right_child(data={\"label\":\"SDTD\"})\n",
    "node21=node2.spawn_left_child(data={\"label\":\"DSTD\"})\n",
    "node22=node2.spawn_right_child(data={\"label\":\"SSTD\"})\n",
    "node211=node21.spawn_left_child(data={\"label\":\"DDSTD\"})\n",
    "node2111=node211.spawn_left_child(data={\"label\":\"DDDSTD\"})\n",
    "node2112=node211.spawn_right_child(data={\"label\":\"SDDSTD\"})\n",
    "node212=node21.spawn_right_child(data={\"label\":\"SDSTD\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node label = DDDSTD\n",
      "   parent label = DDSTD\n",
      "   no left child\n",
      "   no right child\n",
      "\n",
      "node label = DDSTD\n",
      "   parent label = DSTD\n",
      "   left child label DDDSTD\n",
      "   right child label SDDSTD\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(node2111)\n",
    "print(node2111.parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DDSTD'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node2111.parent.data[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 'DDDSTD', 'depth': 4}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node2111.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Traverse the tree - depth first**\n",
    "\n",
    "Once we have created a binary tree, we can recursively traverse it. \n",
    "\n",
    "The following code creates a string consisting of the label + new line character of a node and adjoins the same for its children.\n",
    "\n",
    "A key capability utilized here is that function can call itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_string(node):\n",
    "    s=node.data[\"label\"]+\"\\n\"\n",
    "    if node.left_child!=None:\n",
    "        s+=node_string(node.left_child)\n",
    "    if node.right_child!=None:\n",
    "        s+=node_string(node.right_child)\n",
    "    return(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we compute node_string of a node, that nodes label is stored in s, then if there is a left-child, the label for the left-child is attached and before the label for the right-child is attached, the labels for the children are attached, and so on.\n",
    "\n",
    "Let's try this for the rootnode of our tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TD = Top dog\n",
      "DTD = daughter of Top Dog\n",
      "DDTD\n",
      "SDTD\n",
      "STD = son of Top Dog\n",
      "DSTD\n",
      "DDSTD\n",
      "DDDSTD\n",
      "SDDSTD\n",
      "SDSTD\n",
      "SSTD\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(node_string(rootnode))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using Indents to Represent the \"Child Of\" Relationship**\n",
    "\n",
    "We want to draw a tree using some amount of indentation of children relative to their parent - we indent by a certain amount depending on the depth of a node.\n",
    "\n",
    "We can use the join function to create strings with some amount of indentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cat:::bird:::dog:::turtle'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\":::\".join([\"cat\",\"bird\",\"dog\",\"turtle\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mystring\n",
      " mystring\n",
      "  mystring\n",
      "   mystring\n",
      "    mystring\n",
      "     mystring\n",
      "      mystring\n",
      "       mystring\n",
      "        mystring\n",
      "         mystring\n"
     ]
    }
   ],
   "source": [
    "for n in range(10):\n",
    "    # create string with n spaces \n",
    "    nspaces=\"\".join([\" \" for i in range(n)])\n",
    "    # make spaces prefix for a string\n",
    "    s=nspaces+\"mystring\"\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_string(node):\n",
    "    # create string of spaces with size = depth of node\n",
    "    spaces=\"\".join([\"   \" for i in range(node.data[\"depth\"])])\n",
    "    s=spaces+node.data[\"label\"]+\"\\n\"\n",
    "    if node.left_child!=None:\n",
    "        s+=node_string(node.left_child)\n",
    "    if node.right_child!=None:\n",
    "        s+=node_string(node.right_child)\n",
    "    return(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TD = Top dog\n",
      "   DTD = daughter of Top Dog\n",
      "      DDTD\n",
      "      SDTD\n",
      "   STD = son of Top Dog\n",
      "      DSTD\n",
      "         DDSTD\n",
      "            DDDSTD\n",
      "            SDDSTD\n",
      "         SDSTD\n",
      "      SSTD\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(node_string(rootnode))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our function works for any node "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   DTD = daughter of Top Dog\n",
      "      DDTD\n",
      "      SDTD\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(node_string(rootnode.left_child))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   STD = son of Top Dog\n",
      "      DSTD\n",
      "         DDSTD\n",
      "            DDDSTD\n",
      "            SDDSTD\n",
      "         SDSTD\n",
      "      SSTD\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(node_string(rootnode.right_child))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add class method**\n",
    "\n",
    "As usual, we can make this function a method of our class. When we do that, we need to re-write the function calls so that they look like \"node.node_string()\" instead of \"node-string(node)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TD = Top dog\n",
      " DTD = daughter of Top Dog\n",
      "  DDTD\n",
      "  SDTD\n",
      " STD = son of Top Dog\n",
      "  DSTD\n",
      "   DDSTD\n",
      "    DDDSTD\n",
      "    SDDSTD\n",
      "   SDSTD\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class node:\n",
    "    __slots__=('parent','left_child','right_child','data')\n",
    "    #\n",
    "    # We instantiate a node by passing a parent (which can be None) \n",
    "    # and a dictionary\n",
    "    #\n",
    "    def __init__(self,parent,data={}):\n",
    "        if parent==None:\n",
    "            # making this a root node\n",
    "            self.data=data\n",
    "            self.data[\"depth\"]=0\n",
    "            self.parent=None\n",
    "        else:\n",
    "            # making this a non-root node\n",
    "            self.data=data\n",
    "            self.data[\"depth\"]=parent.data[\"depth\"]+1\n",
    "            self.parent=parent\n",
    "        self.left_child=None\n",
    "        self.right_child=None\n",
    "    def spawn_left_child(self,data={}):\n",
    "        n=node(parent=self,data=data)\n",
    "        n.data=data\n",
    "        n.data[\"depth\"]=self.data[\"depth\"]+1\n",
    "        self.left_child=n\n",
    "        return(n)\n",
    "    def spawn_right_child(self,data={}):\n",
    "        n=node(parent=self,data=data)\n",
    "        n.data=data\n",
    "        n.data[\"depth\"]=self.data[\"depth\"]+1\n",
    "        self.right_child=n\n",
    "        return(n)\n",
    "    #\n",
    "    # string consisting of information about node\n",
    "    #\n",
    "    def __str__(self):\n",
    "        s=\"node label = \"+self.data[\"label\"]+\"\\n\"\n",
    "        if self.parent==None:\n",
    "            s+=\"   no parent i.e. root node\\n\"\n",
    "        else:\n",
    "            s+=\"   parent label = \" + self.parent.data[\"label\"]+\"\\n\"\n",
    "        if self.left_child==None:\n",
    "            s+=\"   no left child\\n\"\n",
    "        else:\n",
    "            s+=\"   left child label \" + self.left_child.data[\"label\"]+\"\\n\"\n",
    "        if self.right_child==None:\n",
    "            s+=\"   no right child\\n\"\n",
    "        else:\n",
    "            s+=\"   right child label \" + self.right_child.data[\"label\"]+\"\\n\"\n",
    "        \n",
    "        return(s)\n",
    "    def node_string(self):\n",
    "        spaces=\"\".join([\" \" for i in range(self.data[\"depth\"])])\n",
    "        s=spaces+self.data[\"label\"]+\"\\n\"\n",
    "        if self.left_child!=None:\n",
    "            s+=self.left_child.node_string()\n",
    "        if self.right_child!=None:\n",
    "            s+=self.right_child.node_string()\n",
    "        return(s)\n",
    "rootnode=node(parent=None,data={\"label\":\"TD = Top dog\"})\n",
    "node1=rootnode.spawn_left_child(data={\"label\":\"DTD = daughter of Top Dog\"})\n",
    "node2=rootnode.spawn_right_child(data={\"label\":\"STD = son of Top Dog\"})\n",
    "node11=node1.spawn_left_child(data={\"label\":\"DDTD\"})\n",
    "node12=node1.spawn_right_child(data={\"label\":\"SDTD\"})\n",
    "node21=node2.spawn_left_child(data={\"label\":\"DSTD\"})\n",
    "node211=node21.spawn_left_child(data={\"label\":\"DDSTD\"})\n",
    "node2111=node211.spawn_left_child(data={\"label\":\"DDDSTD\"})\n",
    "node2112=node211.spawn_right_child(data={\"label\":\"SDDSTD\"})\n",
    "node212=node21.spawn_right_child(data={\"label\":\"SDSTD\"})\n",
    "\n",
    "s=rootnode.node_string()\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   DDSTD\n",
      "    DDDSTD\n",
      "    SDDSTD\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s211=node211.node_string()\n",
    "print(s211)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Binary Decision Trees**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A binary decision tree is a binary tree that enables us to predict which category an item falls into based on known characteristics of the item. Here is a simple example from finance. Mortgage loans have the following attributes:\n",
    "\n",
    "- location type (suburban, rural, urban)\n",
    "- borrower's credit score (numerical)\n",
    "- loan principle i.e. size of loan (numerical)\n",
    "- interest rate (numerical)\n",
    " \n",
    "A loan can either be approved or not. We have lots of loan performance data, and based on that, here might be an example of a (by no means realistic) classifier:\n",
    "\n",
    "* location = rural or suburban\n",
    "    * credit score>700\n",
    "        * interest rate>5% => reject\n",
    "        * interest rate<=5% => approve\n",
    "    * credit score<=700 => reject\n",
    "* location = urban\n",
    "    * credit score > 650\n",
    "        * principle > 100K => approve\n",
    "        * principle <= 100K => reject\n",
    "    * credit score <= 650 => reject\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A leaf is a node of a tree that has no chilren. \n",
    "\n",
    "Note the tree structure. We can think of a binary decision tree as a binary tree such that, to classifiy an individual with given variable values we start at the root node and move along a path picking a child node at each step from the current node. Every non leaf has two children and a function at the node, which upon evaluation. Every leaf node has a category and we classify an individual according to the category of the leaf node they ultimately reach.\n",
    "\n",
    "**Key point:** We can include any type of Python object as a node dictionary value- including a function.\n",
    "\n",
    "Below, we add a key \"f\" and make the value one of the functions defined below to every node dictionary.\n",
    "\n",
    "Each function takes as input a dictionary with keys being \"location\", \"credit score\", \"interest rate\", and\n",
    "\"principle\" representing properties of a loan to approve or disapprove.\n",
    "\n",
    "We place a label at each node so that we can see what is going on in the code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some functions\n",
    "def f0(x):\n",
    "    if x[\"location\"]==\"rural\" or x[\"location\"]==\"suburban\":\n",
    "        return(\"left\")\n",
    "    else:\n",
    "        return(\"right\")\n",
    "\n",
    "def f1(x):\n",
    "    if x[\"credit score\"]>700:\n",
    "        return(\"left\")\n",
    "    else:\n",
    "        return(\"right\")\n",
    "\n",
    "def f2(x):\n",
    "    if x[\"credit score\"]>650:\n",
    "        return(\"left\")\n",
    "    else:\n",
    "        return(\"right\")\n",
    "    \n",
    "def f11(x):\n",
    "    if x[\"interest rate\"]>5:\n",
    "        return(\"left\")\n",
    "    else:\n",
    "        return(\"right\")\n",
    "def f111(x):\n",
    "    return(\"reject\")\n",
    "def f112(x):\n",
    "    return(\"approve\")\n",
    "def f12(x):\n",
    "    return(\"reject\")\n",
    "\n",
    "def f21(x):\n",
    "    if x[\"principle\"]>100:\n",
    "        return(\"left\")\n",
    "    else:\n",
    "        return(\"right\")\n",
    "def f211(x):\n",
    "    return(\"approve\")\n",
    "def f212(x):\n",
    "    return(\"reject\")\n",
    "def f22(x):\n",
    "    return(\"reject\")\n",
    "#\n",
    "# Create the tree.\n",
    "#\n",
    "rootnode=node(parent=None,data={\"f\":f0,\"label\":\"0\"})\n",
    "node1=rootnode.spawn_left_child(data={\"f\":f1,\"label\":\"1\"})\n",
    "node11=node1.spawn_left_child(data={\"f\":f11,\"label\":\"11\"})\n",
    "node111=node11.spawn_left_child(data={\"f\":f111,\"label\":\"111\"})\n",
    "node112=node11.spawn_right_child(data={\"f\":f112,\"label\":\"112\"})\n",
    "node12=node1.spawn_right_child(data={\"f\":f12,\"label\":\"12\"})\n",
    "node2=rootnode.spawn_right_child(data={\"f\":f2,\"label\":\"2\"})\n",
    "node21=node2.spawn_left_child(data={\"f\":f21,\"label\":\"21\"})\n",
    "node211=node21.spawn_left_child(data={\"f\":f211,\"label\":\"211\"})\n",
    "node212=node21.spawn_right_child(data={\"f\":f212,\"label\":\"212\"})\n",
    "node22=node2.spawn_right_child(data={\"f\":f22,\"label\":\"22\"})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification**\n",
    "\n",
    "The classifier is used to classify a new observation i.e. data for a person seeking a loan.\n",
    "\n",
    "We assume that this data is stored as a dictionary with keys \"location\", \"credit score\", \"interest rate\", \"principle\".\n",
    "\n",
    "Now that we have our tree, we can create a function that uses tree recursion to calculate the action to be taken.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(idata):\n",
    "    # initialize current node at root node\n",
    "    cnode=rootnode\n",
    "    #\n",
    "    # if current node as child nodes, compute function \n",
    "    # to determine which child node to go to\n",
    "    #\n",
    "    while cnode.left_child:\n",
    "        print(\"current node label = \", cnode.data[\"label\"])\n",
    "        #\n",
    "        # compute function value at this node (the result is \"left\" or \"right\")\n",
    "        #\n",
    "        value=cnode.data[\"f\"](idata)\n",
    "        print(\"function value = \",cnode.data[\"f\"](x))\n",
    "        if value==\"left\":\n",
    "            cnode=cnode.left_child\n",
    "        else:\n",
    "            cnode=cnode.right_child\n",
    "    #\n",
    "    # current node has no children - we are at a leaf\n",
    "    #\n",
    "    value=cnode.data[\"f\"](idata)\n",
    "    print(\"current node label = \", cnode.data[\"label\"])\n",
    "    print(\"function value = \"+value)\n",
    "    return(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current node label =  0\n",
      "function value =  right\n",
      "current node label =  2\n",
      "function value =  left\n",
      "current node label =  21\n",
      "function value =  left\n",
      "current node label =  211\n",
      "function value = approve\n",
      "\n",
      "approve\n"
     ]
    }
   ],
   "source": [
    "x={\"location\":\"urban\",\"credit score\":680,\"interest rate\":6.5,\"principle\":300}\n",
    "result=classify(x)\n",
    "print(\"\\n\"+result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prediction with probabilities**\n",
    "\n",
    "When predicting a binary outcome (rain/no-rain tomomrrow, loan defaults/load doesn't default, patient survives/patient dies) based on data, it is more informative to report a probability rather than the outcome itself. This has the benefit\n",
    "\n",
    "- the probability reflects uncertainty\n",
    "- the decision-maker can compute an expected loss associated with either decision and act accordingly\n",
    "\n",
    "To illustrate, suppose you know that the chance of a hurricaine hitting Miami tomorrow is 10%. Suppose the loss associated with not preparing for the possibility of a hurricaine when it actually hits is \\\\$ 100,000 and the loss associated with preparing and having it not hit is \\\\$ 500. Then \n",
    "\n",
    "- Expected loss if you don't prepare $E(P=0)=100000(0.1)+0(0.9) = 10,000$  \n",
    "- Expected loss if you do prepare $E(P=1)=0(0.1)+500(0.9) = 450$  \n",
    "\n",
    "So in terms of minizing expected loss it is better to prepare. On the other hand, if the probability of the hurricaine hitting is 1 in 50,000, then by this criterion you ought not prepare.\n",
    "\n",
    "The above is easily modified to return a probability of default (estimated)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current node label =  0\n",
      "function value =  right\n",
      "current node label =  2\n",
      "function value =  right\n",
      "current node label =  22\n",
      "function value = 0.08\n",
      "\n",
      "0.08\n"
     ]
    }
   ],
   "source": [
    "def f0(x):\n",
    "    if x[\"location\"]==\"rural\" or x[\"location\"]==\"suburban\":\n",
    "        return(\"left\")\n",
    "    else:\n",
    "        return(\"right\")\n",
    "\n",
    "def f1(x):\n",
    "    if x[\"credit score\"]>700:\n",
    "        return(\"left\")\n",
    "    else:\n",
    "        return(\"right\")\n",
    "\n",
    "def f2(x):\n",
    "    if x[\"credit score\"]>650:\n",
    "        return(\"left\")\n",
    "    else:\n",
    "        return(\"right\")\n",
    "    \n",
    "def f11(x):\n",
    "    if x[\"interest rate\"]>5:\n",
    "        return(\"left\")\n",
    "    else:\n",
    "        return(\"right\")\n",
    "def f111(x):\n",
    "    return(.23)\n",
    "def f112(x):\n",
    "    return(.05)\n",
    "def f12(x):\n",
    "    return(.17)\n",
    "\n",
    "def f21(x):\n",
    "    if x[\"principle\"]>100:\n",
    "        return(\"left\")\n",
    "    else:\n",
    "        return(\"right\")\n",
    "def f211(x):\n",
    "    return(.04)\n",
    "def f212(x):\n",
    "    return(.09)\n",
    "def f22(x):\n",
    "    return(.08)\n",
    "\n",
    "rootnode=node(parent=None,data={\"f\":f0,\"label\":\"0\"})\n",
    "node1=rootnode.spawn_left_child(data={\"f\":f1,\"label\":\"1\"})\n",
    "node11=node1.spawn_left_child(data={\"f\":f11,\"label\":\"11\"})\n",
    "node111=node11.spawn_left_child(data={\"f\":f111,\"label\":\"111\"})\n",
    "node112=node11.spawn_right_child(data={\"f\":f112,\"label\":\"112\"})\n",
    "node12=node1.spawn_right_child(data={\"f\":f12,\"label\":\"12\"})\n",
    "node2=rootnode.spawn_right_child(data={\"f\":f2,\"label\":\"2\"})\n",
    "node21=node2.spawn_left_child(data={\"f\":f21,\"label\":\"21\"})\n",
    "node211=node21.spawn_left_child(data={\"f\":f211,\"label\":\"211\"})\n",
    "node212=node21.spawn_right_child(data={\"f\":f212,\"label\":\"212\"})\n",
    "node22=node2.spawn_right_child(data={\"f\":f22,\"label\":\"22\"})\n",
    "\n",
    "def classify(idata):\n",
    "    # initialize current node at root node\n",
    "    cnode=rootnode\n",
    "    #\n",
    "    # if current node as child nodes, compute function \n",
    "    # to determine which child node to go to\n",
    "    #\n",
    "    while cnode.left_child:\n",
    "        print(\"current node label = \", cnode.data[\"label\"])\n",
    "        #\n",
    "        # compute function value at this node (the result is \"left\" or \"right\")\n",
    "        #\n",
    "        value=cnode.data[\"f\"](idata)\n",
    "        print(\"function value = \",cnode.data[\"f\"](x))\n",
    "        if value==\"left\":\n",
    "            cnode=cnode.left_child\n",
    "        else:\n",
    "            cnode=cnode.right_child\n",
    "    #\n",
    "    # current node has no children - we are at a leaf\n",
    "    #\n",
    "    value=cnode.data[\"f\"](idata)\n",
    "    print(\"current node label = \", cnode.data[\"label\"])\n",
    "    print(\"function value = \"+str(value))\n",
    "    return(value)\n",
    "x={\"location\":\"urban\",\"credit score\":500,\"interest rate\":7,\"principle\":90}\n",
    "result=classify(x)\n",
    "print(\"\\n\"+str(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building Binary Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Building a Binary Decision Tree from Data**\n",
    "\n",
    "Suppose we have a dataset with some predictor variables $x_1,x_2,\\ldots,x_k$ and binary response variable $Y.$ For example, for the mortgage dataset we have predictors (location, principal, interest rate, credit score) and we want to predict the result (default, non-default). Our datset is _flat_/_rectangular_, with N rows and $k+1$ columns, with one column for each variable and one row for each _observation_ (mortgage loan).\n",
    "\n",
    "We wish to use these data to build a decision tree in which the functions at the nodes are functions of the the predictor variables. \n",
    "\n",
    "Assume $Y$ takes the value 0 or 1. \n",
    "\n",
    "The predictor variables can be categorical or continuous."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recursive Description of the Algorithm**\n",
    "\n",
    "The algorithm for building the tree has a recursive definition.\n",
    "\n",
    "We begin by creating a root node with the entire dataset as attached to that node.\n",
    "\n",
    "We start at the root node.\n",
    "\n",
    "Whenever we visit a node, we compute and store at the node the following information about the dataset attached to the node:\n",
    "\n",
    "a) the number of observations in the dataset attached to that node, and \n",
    "\n",
    "b) the proportion of observations in each class (Y=0 or 1)\n",
    "\n",
    "Next, we take one of the following actions:\n",
    "\n",
    "1) Find a function (splitting function) that splits/partitions the data into two pieces. The two pieces should look different in the sense that one piece tends to have a different proportions of observations with Y=1, and the pieces are each sufficiently large. Call these pieces left piece and right piece. If such a _split_ can be found, we attach the splitting function to the node, spawn two children of the current node, attach piece \\#1 to the left child  and piece \\#2 to the right child, and visit each of those children. \n",
    "\n",
    "or\n",
    "\n",
    "2) Determine that a splitting function cannot be found so the current node becomes a leaf node (no children). \n",
    "\n",
    "The splitting function should be a function of $x_1,x_2,...,x_k$ that returns a value of \"left\" or \"right\". Typically, this function is taken to be a function of only one of the $x_i$'s and \n",
    "\n",
    "a) for a continuous variable this is a function of the form:  if $xi < c$ return(\"left\") else return(\"right)\n",
    "\n",
    "b) for a categorical variable, this function takes the form: if $x \\in I$ return(\"left\") else return(\"right\") where $I$ is a subset of the values that the variable can take."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How to Classify/Predict $Y$ for a New Observation**\n",
    "\n",
    "Given a new observation with predictor variables $x1,x2,\\ldots,xk$ we start at the root node and for each node we visit, we do one of the following:\n",
    "\n",
    "a) if the node has chilren, apply the splitting function at the current node to determine which child node to visit next, or\n",
    "\n",
    "b) if the current node is a leaf node, return the proportion $p_1$ of observations with $Y=1$ at that node\n",
    "\n",
    "Finally, we predict $Y=1$ if $p_1$ exceeds some pre-determined threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Splitting Criterion - how to find a good splitting function**\n",
    "\n",
    "We need a criterion for deciding on a good splitting function. There are several possibilities. We focus here on the Gini index.\n",
    "\n",
    "Given a categorical variable taking K possible values and a set of data for that variable with proportions $p_1,p_2,\\ldots,p_K$ of values in each category we define the Gini index by\n",
    "\n",
    "$$ G = \\sum_{i=1}^k p_i(1-p_i)$$\n",
    "\n",
    "This number has the following interpretation. If we pick a data point at random, and classify it as class 1 with probability $p_1,$ class 2 with probability $p_2,$ etc., $G$ is the probability of incorrectly classifying that observation.\n",
    "\n",
    "$G$ is a measure of _impurity_ of the dataset with regard to the class variable, if one of the $p_i$ is one and the others are zero (perfect _purity_) we get $G=0.$ In in the case of a binary class variable, with $p_1=p_2=1/2$ we get $G =1/2.$ \n",
    "\n",
    "When we split out dataset into two pieces, we would like the two child datasets to be as pure as possible so we try to minimize the quantity\n",
    "\n",
    "$$ N_{left} G_{left} + N_{right} G_{right}$$\n",
    "\n",
    "that is, the weighted sum of the impurities of the child datasets weighted by the number of observations in the datasets.\n",
    "\n",
    "It is typical to require for splitting that the size of each child dataaet be above some pre-determined threshold.\n",
    "\n",
    "Lower Gini is better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>princ</th>\n",
       "      <th>irate</th>\n",
       "      <th>cscore</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>suburban</td>\n",
       "      <td>358</td>\n",
       "      <td>7.00</td>\n",
       "      <td>728</td>\n",
       "      <td>default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>suburban</td>\n",
       "      <td>637</td>\n",
       "      <td>7.25</td>\n",
       "      <td>675</td>\n",
       "      <td>default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>suburban</td>\n",
       "      <td>303</td>\n",
       "      <td>7.25</td>\n",
       "      <td>645</td>\n",
       "      <td>non-default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>suburban</td>\n",
       "      <td>397</td>\n",
       "      <td>7.25</td>\n",
       "      <td>609</td>\n",
       "      <td>non-default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>suburban</td>\n",
       "      <td>420</td>\n",
       "      <td>7.75</td>\n",
       "      <td>669</td>\n",
       "      <td>default</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   location  princ  irate  cscore       result\n",
       "0  suburban    358   7.00     728      default\n",
       "1  suburban    637   7.25     675      default\n",
       "2  suburban    303   7.25     645  non-default\n",
       "3  suburban    397   7.25     609  non-default\n",
       "4  suburban    420   7.75     669      default"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "mdata=pd.read_csv(\"mortgage_data.csv\")\n",
    "print(type(mdata))\n",
    "mdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>princ</th>\n",
       "      <th>irate</th>\n",
       "      <th>cscore</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9859</th>\n",
       "      <td>suburban</td>\n",
       "      <td>769</td>\n",
       "      <td>7.75</td>\n",
       "      <td>586</td>\n",
       "      <td>non-default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9860</th>\n",
       "      <td>suburban</td>\n",
       "      <td>451</td>\n",
       "      <td>7.25</td>\n",
       "      <td>684</td>\n",
       "      <td>non-default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9861</th>\n",
       "      <td>suburban</td>\n",
       "      <td>410</td>\n",
       "      <td>7.00</td>\n",
       "      <td>702</td>\n",
       "      <td>non-default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9862</th>\n",
       "      <td>suburban</td>\n",
       "      <td>851</td>\n",
       "      <td>7.00</td>\n",
       "      <td>774</td>\n",
       "      <td>non-default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9863</th>\n",
       "      <td>suburban</td>\n",
       "      <td>260</td>\n",
       "      <td>7.50</td>\n",
       "      <td>657</td>\n",
       "      <td>default</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      location  princ  irate  cscore       result\n",
       "9859  suburban    769   7.75     586  non-default\n",
       "9860  suburban    451   7.25     684  non-default\n",
       "9861  suburban    410   7.00     702  non-default\n",
       "9862  suburban    851   7.00     774  non-default\n",
       "9863  suburban    260   7.50     657      default"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdata.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9864, 5)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "location    suburban\n",
       "princ            420\n",
       "irate           7.75\n",
       "cscore           669\n",
       "result       default\n",
       "Name: 4, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdata.loc[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Create a Y variable - Y=1 for default Y=0 for non-default\n",
    "#\n",
    "def f(row):\n",
    "    if row[\"result\"]==\"default\":\n",
    "        return(1)\n",
    "    else:\n",
    "        return(0)\n",
    "mdata[\"Y\"]=mdata.apply(f,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>princ</th>\n",
       "      <th>irate</th>\n",
       "      <th>cscore</th>\n",
       "      <th>result</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>suburban</td>\n",
       "      <td>358</td>\n",
       "      <td>7.00</td>\n",
       "      <td>728</td>\n",
       "      <td>default</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>suburban</td>\n",
       "      <td>637</td>\n",
       "      <td>7.25</td>\n",
       "      <td>675</td>\n",
       "      <td>default</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>suburban</td>\n",
       "      <td>303</td>\n",
       "      <td>7.25</td>\n",
       "      <td>645</td>\n",
       "      <td>non-default</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>suburban</td>\n",
       "      <td>397</td>\n",
       "      <td>7.25</td>\n",
       "      <td>609</td>\n",
       "      <td>non-default</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>suburban</td>\n",
       "      <td>420</td>\n",
       "      <td>7.75</td>\n",
       "      <td>669</td>\n",
       "      <td>default</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9859</th>\n",
       "      <td>suburban</td>\n",
       "      <td>769</td>\n",
       "      <td>7.75</td>\n",
       "      <td>586</td>\n",
       "      <td>non-default</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9860</th>\n",
       "      <td>suburban</td>\n",
       "      <td>451</td>\n",
       "      <td>7.25</td>\n",
       "      <td>684</td>\n",
       "      <td>non-default</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9861</th>\n",
       "      <td>suburban</td>\n",
       "      <td>410</td>\n",
       "      <td>7.00</td>\n",
       "      <td>702</td>\n",
       "      <td>non-default</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9862</th>\n",
       "      <td>suburban</td>\n",
       "      <td>851</td>\n",
       "      <td>7.00</td>\n",
       "      <td>774</td>\n",
       "      <td>non-default</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9863</th>\n",
       "      <td>suburban</td>\n",
       "      <td>260</td>\n",
       "      <td>7.50</td>\n",
       "      <td>657</td>\n",
       "      <td>default</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9864 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      location  princ  irate  cscore       result  Y\n",
       "0     suburban    358   7.00     728      default  1\n",
       "1     suburban    637   7.25     675      default  1\n",
       "2     suburban    303   7.25     645  non-default  0\n",
       "3     suburban    397   7.25     609  non-default  0\n",
       "4     suburban    420   7.75     669      default  1\n",
       "...        ...    ...    ...     ...          ... ..\n",
       "9859  suburban    769   7.75     586  non-default  0\n",
       "9860  suburban    451   7.25     684  non-default  0\n",
       "9861  suburban    410   7.00     702  non-default  0\n",
       "9862  suburban    851   7.00     774  non-default  0\n",
       "9863  suburban    260   7.50     657      default  1\n",
       "\n",
       "[9864 rows x 6 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdata[\"Y\"][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>princ</th>\n",
       "      <th>irate</th>\n",
       "      <th>cscore</th>\n",
       "      <th>result</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>suburban</td>\n",
       "      <td>358</td>\n",
       "      <td>7.00</td>\n",
       "      <td>728</td>\n",
       "      <td>default</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>suburban</td>\n",
       "      <td>637</td>\n",
       "      <td>7.25</td>\n",
       "      <td>675</td>\n",
       "      <td>default</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>suburban</td>\n",
       "      <td>303</td>\n",
       "      <td>7.25</td>\n",
       "      <td>645</td>\n",
       "      <td>non-default</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>suburban</td>\n",
       "      <td>397</td>\n",
       "      <td>7.25</td>\n",
       "      <td>609</td>\n",
       "      <td>non-default</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>suburban</td>\n",
       "      <td>420</td>\n",
       "      <td>7.75</td>\n",
       "      <td>669</td>\n",
       "      <td>default</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   location  princ  irate  cscore       result  Y\n",
       "0  suburban    358   7.00     728      default  1\n",
       "1  suburban    637   7.25     675      default  1\n",
       "2  suburban    303   7.25     645  non-default  0\n",
       "3  suburban    397   7.25     609  non-default  0\n",
       "4  suburban    420   7.75     669      default  1"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "location\n",
       "suburban    5347\n",
       "urban       2423\n",
       "rural       2094\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdata[\"location\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate quality of a split**\n",
    "\n",
    "Let's write code to evaluate quality of an example of a splitting function.\n",
    "\n",
    "That code should take a pandas data frame and a function as arguments.\n",
    "\n",
    "If a split would produce nodes with sizes below some threshold, we return a value so large that it can't reduce Gini coefficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example of a splitting function**\n",
    "\n",
    "Here, we classify a row (an observation) according to whether the **cscore** for that row exceeds some threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(row):\n",
    "    if row[\"cscore\"]>550:\n",
    "        return(\"left\")\n",
    "    else:\n",
    "        return(\"right\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gini criterion**\n",
    "\n",
    "The following function takes as an argument a function, a data frame, and a minimum node size, and calcultes the Gini criterion.\n",
    "\n",
    "If splitting produces a node that has too few observations (less than min_node_size) we return a large value so that we'll not choose this splitting function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gini_criterion(df,f,min_node_size):\n",
    "    #\n",
    "    # calculate f(row) for every row in the data frame\n",
    "    # this produces a Pandas series\n",
    "    #\n",
    "    fvalue=df.apply(f,axis=1)\n",
    "    #\n",
    "    # get the series of Y's for which fvalue is \"left\" \n",
    "    # and the series of Y's for whcih fvalue is \"right\"\n",
    "    #\n",
    "    Yleft=df[\"Y\"].loc[fvalue==\"left\"]\n",
    "    Yright=df[\"Y\"].loc[fvalue==\"right\"]\n",
    "    #\n",
    "    # compute number of obs in each side\n",
    "    #\n",
    "    nleft=Yleft.size\n",
    "    nright=Yright.size\n",
    "    #\n",
    "    # if split puts too few values in a node\n",
    "    # we return a value that makes it so we'd never choose this f\n",
    "    #\n",
    "    if nleft<min_node_size or nright<min_node_size:\n",
    "        return(nleft+nright)\n",
    "    \n",
    "    p1left=Yleft.loc[Yleft==1].size/nleft\n",
    "    p1right=Yright.loc[Yright==1].size/nright\n",
    "    #\n",
    "    # compute the Gini coefficient\n",
    "    #\n",
    "    Gini=Yleft.size*p1left*(1-p1left)+Yright.size*p1right*(1-p1right)\n",
    "    return(Gini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2282.2216076097498\n"
     ]
    }
   ],
   "source": [
    "ginivalue=Gini_criterion(mdata,f,100)\n",
    "print(ginivalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Another example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(row):\n",
    "    if row[\"irate\"]>7:\n",
    "        return(\"left\")\n",
    "    else:\n",
    "        return(\"right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2121.446715049349\n"
     ]
    }
   ],
   "source": [
    "ginivalue=Gini_criterion(mdata,f,100)\n",
    "print(ginivalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal**\n",
    "\n",
    "We want our children to be as pure as possible, and we see that Gini impurity is lower for this splitting function than the one above, so this one would be preferred. We can ask for the best possible split based on a continuous variable or a categorical variable.\n",
    "\n",
    "For a continuous variable v we could try every possible split of the form: $v<c$ vs. $v>c$ but that might take too long to compute. Instead we try only using some quantiles  for that variable. Below, quartiles are used, but there are other options, e.g. deciles, percentiles.\n",
    "\n",
    "If a split would produce a node with too few values, we return a huge gini value (one that can't be smaller than the current one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_splitting_function_continuous_variable(data,vname,min_node_size):\n",
    "    qvalues=[data[vname].quantile(i/20) for i in range(1,20)]\n",
    "    minginivalue=mdata.shape[0] # Gini can't be this big\n",
    "    for qvalue in qvalues:\n",
    "        def f(row):\n",
    "            if row[vname]<qvalue:\n",
    "                return(\"left\")\n",
    "            else:\n",
    "                return(\"right\")\n",
    "        ginivalue=Gini_criterion(data,f,min_node_size)\n",
    "        if ginivalue<minginivalue:\n",
    "            bestf=f\n",
    "            bestvalue=qvalue\n",
    "            minginivalue=ginivalue\n",
    "    #\n",
    "    # return the best function, the value and its gini value\n",
    "    #\n",
    "    return(bestf,bestvalue,minginivalue)  \n",
    "    #return(bestf,minginivalue)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2283.100845967919\n"
     ]
    }
   ],
   "source": [
    "f,v,g=find_best_splitting_function_continuous_variable(mdata,\"cscore\",100)\n",
    "#f,g=find_best_splitting_function_continuous_variable(mdata,\"cscore\",100)\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** In this function, we save the best function and the best threshold.\n",
    "But isn't the threshold included in that best function? Let's look at a simplified example of the phenomenon under consideration. Let's find function that roughly splits a data array at the median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def find_best_function(x):\n",
    "    minvalue=10000000\n",
    "    #\n",
    "    # Try thresholds in range from 0 to 10 in steps of\n",
    "    # size 0.1\n",
    "    #\n",
    "    for tau in np.linspace(0,10,100):\n",
    "        def f(u):\n",
    "            if u<tau:\n",
    "                return(\"left\")\n",
    "            else:\n",
    "                return(\"right\")\n",
    "        #\n",
    "        # determine how well this f performs\n",
    "        # we want the number left as close as\n",
    "        # possible to the number right\n",
    "        #\n",
    "        y=list(map(f,x))\n",
    "        nleft=y.count(\"left\")\n",
    "        nright=y.count(\"right\")\n",
    "        value=np.abs(nleft-nright)\n",
    "        if value<minvalue:\n",
    "            bestf=f\n",
    "            minvalue=value\n",
    "    return bestf\n",
    "#\n",
    "# Determine best f for an example of a list of numbers\n",
    "#\n",
    "x=list(np.random.normal(5,1,25))\n",
    "f=find_best_function(x)\n",
    "y=list(map(f,x))\n",
    "nleft=y.count(\"left\")\n",
    "nright=y.count(\"right\")\n",
    "print(nleft)\n",
    "print(nright)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This does not do the right thing. Do you see why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def find_best_function(x):\n",
    "    minvalue=10000000\n",
    "    #\n",
    "    # Try thresholds in range from 0 to 10 in steps of\n",
    "    # size 0.1\n",
    "    #\n",
    "    for tau in np.linspace(0,10,100):\n",
    "        def f(u):\n",
    "            if u<tau:\n",
    "                return(\"left\")\n",
    "            else:\n",
    "                return(\"right\")\n",
    "        #\n",
    "        # determine how well this f performs\n",
    "        # we want the number left as close as\n",
    "        # possible to the number right\n",
    "        #\n",
    "        y=list(map(f,x))\n",
    "        nleft=y.count(\"left\")\n",
    "        nright=y.count(\"right\")\n",
    "        value=np.abs(nleft-nright)\n",
    "        if value<minvalue:\n",
    "            besttau=tau\n",
    "            minvalue=value\n",
    "    def f(u):\n",
    "        if u<besttau:\n",
    "            return(\"left\")\n",
    "        else:\n",
    "            return(\"right\")\n",
    "    return f\n",
    "#\n",
    "# Determine best f for an example of a list of numbers\n",
    "#\n",
    "x=list(np.random.normal(5,1,25))\n",
    "f=find_best_function(x)\n",
    "y=list(map(f,x))\n",
    "nleft=y.count(\"left\")\n",
    "nright=y.count(\"right\")\n",
    "print(nleft)\n",
    "print(nright)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.0\n",
      "2108.0970094988857\n"
     ]
    }
   ],
   "source": [
    "f,v,g=find_best_splitting_function_continuous_variable(mdata,\"irate\",100)\n",
    "print(v)\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Splits for a categorical variable**\n",
    "\n",
    "We need a function to try all splits of a categorical variable v taking values in a set say S={1,2,3,...,K}\n",
    "\n",
    "Here we try splitting on a given subset T of S -sending those observations with values of v in T to the left and the others to the right.\n",
    "\n",
    "We can then iterate over all nonempty subsets T to find the minimizer of the Gini criterion - Note that this code is less than optimal because every set is tested twice - once when we send observations with values in T to the left and again when we send all observations in the complement of T to the left.\n",
    "\n",
    "The itertools package is handy for getting all combinations of elements in a list of some size.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 2), (1, 3), (1, 4), (2, 3), (2, 4), (3, 4)]\n"
     ]
    }
   ],
   "source": [
    "import itertools as it\n",
    "L=list(it.combinations([1,2,3,4],2))\n",
    "print(L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Getting all subsets**\n",
    "\n",
    "We need a list of all ways we can split a list of values into two nonempty pieces. This is straightforward if n, the size of the list is odd, we just need to make a list of all subsets of size 1,2,...,(n-1)/2. But if n is even we don't want to check each split of a subset of size n/2 twice (once for the subset and once for its complement)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_set_splits(value_list):\n",
    "    splits=[]\n",
    "    n=len(value_list)\n",
    "    m=int(n/2)\n",
    "    for sz in range(1,m+1):\n",
    "        combs=it.combinations(value_list,sz)\n",
    "        for comb in combs:\n",
    "            splits.append(list(comb))\n",
    "    if 2*m<n:\n",
    "        return(splits)\n",
    "    #\n",
    "    # even case - need to add in subsets of size n/2\n",
    "    #\n",
    "    combs=it.combinations(value_list,m+1)\n",
    "    svalue_list=set(value_list) # by the way - sets can't contain mutable elements!!!\n",
    "    for comb in combs:\n",
    "        s=set(comb)\n",
    "        sc=svalue_list.difference(s)\n",
    "        if s not in splits and svalue_list.difference(s):\n",
    "            splits.append(list(s))\n",
    "    return(splits)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['dog'], ['cat'], ['bird']]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_all_set_splits(['dog',\"cat\",\"bird\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['dog'],\n",
       " ['cat'],\n",
       " ['bird'],\n",
       " ['turtle'],\n",
       " ['fish'],\n",
       " ['gerble'],\n",
       " ['dog', 'cat'],\n",
       " ['dog', 'bird'],\n",
       " ['dog', 'turtle'],\n",
       " ['dog', 'fish'],\n",
       " ['dog', 'gerble'],\n",
       " ['cat', 'bird'],\n",
       " ['cat', 'turtle'],\n",
       " ['cat', 'fish'],\n",
       " ['cat', 'gerble'],\n",
       " ['bird', 'turtle'],\n",
       " ['bird', 'fish'],\n",
       " ['bird', 'gerble'],\n",
       " ['turtle', 'fish'],\n",
       " ['turtle', 'gerble'],\n",
       " ['fish', 'gerble'],\n",
       " ['dog', 'cat', 'bird'],\n",
       " ['dog', 'cat', 'turtle'],\n",
       " ['dog', 'cat', 'fish'],\n",
       " ['dog', 'cat', 'gerble'],\n",
       " ['dog', 'bird', 'turtle'],\n",
       " ['dog', 'bird', 'fish'],\n",
       " ['dog', 'bird', 'gerble'],\n",
       " ['dog', 'turtle', 'fish'],\n",
       " ['dog', 'turtle', 'gerble'],\n",
       " ['dog', 'fish', 'gerble'],\n",
       " ['cat', 'bird', 'turtle'],\n",
       " ['cat', 'bird', 'fish'],\n",
       " ['cat', 'bird', 'gerble'],\n",
       " ['cat', 'turtle', 'fish'],\n",
       " ['cat', 'turtle', 'gerble'],\n",
       " ['cat', 'fish', 'gerble'],\n",
       " ['bird', 'turtle', 'fish'],\n",
       " ['bird', 'turtle', 'gerble'],\n",
       " ['bird', 'fish', 'gerble'],\n",
       " ['turtle', 'fish', 'gerble'],\n",
       " ['cat', 'turtle', 'dog', 'bird'],\n",
       " ['cat', 'fish', 'dog', 'bird'],\n",
       " ['cat', 'dog', 'gerble', 'bird'],\n",
       " ['cat', 'fish', 'turtle', 'dog'],\n",
       " ['cat', 'turtle', 'dog', 'gerble'],\n",
       " ['cat', 'fish', 'dog', 'gerble'],\n",
       " ['bird', 'fish', 'turtle', 'dog'],\n",
       " ['bird', 'turtle', 'dog', 'gerble'],\n",
       " ['bird', 'fish', 'dog', 'gerble'],\n",
       " ['fish', 'turtle', 'dog', 'gerble'],\n",
       " ['cat', 'fish', 'turtle', 'bird'],\n",
       " ['cat', 'turtle', 'bird', 'gerble'],\n",
       " ['cat', 'fish', 'bird', 'gerble'],\n",
       " ['cat', 'fish', 'turtle', 'gerble'],\n",
       " ['bird', 'fish', 'turtle', 'gerble']]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_all_set_splits([\"dog\",\"cat\",\"bird\",\"turtle\",\"fish\",\"gerble\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_splitting_function_categorical_variable(data,vname,min_node_size):\n",
    "    values=list(data[vname].unique())\n",
    "    nvalues=len(values)\n",
    "    minginivalue=data.shape[0] # Gini can't be this big\n",
    "    subset_list=find_all_set_splits(values)\n",
    "    for subset in subset_list:\n",
    "        def f(row):\n",
    "            if row[vname] in subset:\n",
    "                return(\"left\")\n",
    "            else:\n",
    "                return(\"right\")\n",
    "        ginivalue=Gini_criterion(data,f,min_node_size)\n",
    "        if ginivalue<minginivalue:\n",
    "            bestf=f\n",
    "            bestsubset=subset\n",
    "            minginivalue=ginivalue\n",
    "    return(bestf,bestsubset,minginivalue)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rural']\n",
      "2242.2295523521884\n"
     ]
    }
   ],
   "source": [
    "bestf,bestsubset,minginivalue=find_best_splitting_function_categorical_variable(mdata,\"location\",100)\n",
    "print(bestsubset)\n",
    "print(minginivalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finding best split using all variables (continuous & categorical)**\n",
    "\n",
    "Now we can try all continuous *and* categorical variables looking for the best split.\n",
    "\n",
    "The following function takes a data set, a list of continuous variables, and a list of categorical variables as input and finds the best function to split the data on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<function __main__.find_best_splitting_function_continuous_variable.<locals>.f(row)>,\n",
       " 'irate',\n",
       " 'continuous',\n",
       " np.float64(7.0),\n",
       " 2108.0970094988857)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_best_split(data,cont_vars,cat_vars,min_node_size):\n",
    "    minginivalue=data.shape[0]\n",
    "    for catvar in cat_vars:\n",
    "        f,b,g=find_best_splitting_function_categorical_variable(data,catvar,min_node_size)\n",
    "        if g<minginivalue:\n",
    "            minginivalue=g\n",
    "            bestvar=catvar\n",
    "            bestvartype=\"categorical\"\n",
    "            bestvalue=b\n",
    "            bestf=f\n",
    "    for contvar in cont_vars:\n",
    "        f,b,g=find_best_splitting_function_continuous_variable(data,contvar,min_node_size)\n",
    "        if g<minginivalue:\n",
    "            minginivalue=g\n",
    "            bestvar=contvar\n",
    "            bestvartype=\"continuous\"\n",
    "            bestvalue=b\n",
    "            bestf=f\n",
    "    return bestf,bestvar,bestvartype,bestvalue,minginivalue\n",
    "find_best_split(mdata,[\"irate\",\"cscore\",\"princ\"],[\"location\"],100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build tree recursively**\n",
    "\n",
    "We need a function that builds a tree by starting at root and recursively splitting each node until a stopping rule kicks in.\n",
    "\n",
    "To keep things simple, we'll stop splitting if a node has fewer than 25 observations.\n",
    "\n",
    "Each time we split, we attach a data frame data[\"df\"] to each new node.\n",
    "\n",
    "As we go along, we'll attach the counts of Y=0 and Y=1 to each node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools as it\n",
    "def Gini_criterion(df,f,min_node_size):\n",
    "    #\n",
    "    # calculate f(row) for every row in the data frame\n",
    "    # this produces a Pandas series\n",
    "    #\n",
    "    fvalue=df.apply(f,axis=1)\n",
    "    #\n",
    "    # get the series of Y's for which fvalue is \"left\" \n",
    "    # and the series of Y's for whcih fvalue is \"right\"\n",
    "    #\n",
    "    Yleft=df[\"Y\"].loc[fvalue==\"left\"]\n",
    "    Yright=df[\"Y\"].loc[fvalue==\"right\"]\n",
    "    #\n",
    "    # compute number of obs in each side\n",
    "    #\n",
    "    nleft=Yleft.size\n",
    "    nright=Yright.size\n",
    "    #\n",
    "    # if split puts too few values in a node\n",
    "    # we return a value that makes it so we'd never choose this f\n",
    "    #\n",
    "    if nleft<min_node_size or nright<min_node_size:\n",
    "        return(nleft+nright)\n",
    "    \n",
    "    p1left=Yleft.loc[Yleft==1].size/nleft\n",
    "    p1right=Yright.loc[Yright==1].size/nright\n",
    "    #\n",
    "    # compute the Gini coefficient\n",
    "    #\n",
    "    Gini=Yleft.size*p1left*(1-p1left)+Yright.size*p1right*(1-p1right)\n",
    "    return(Gini)\n",
    "def find_best_splitting_function_continuous_variable(data,vname,min_node_size):\n",
    "    qvalues=[data[vname].quantile(i/4) for i in range(1,4)]\n",
    "    minginivalue=mdata.shape[0] # Gini can't be this big\n",
    "    bestf=None\n",
    "    bestvalue=None\n",
    "    for qvalue in qvalues:\n",
    "        def f(row):\n",
    "            if row[vname]<qvalue:\n",
    "                return(\"left\")\n",
    "            else:\n",
    "                return(\"right\")\n",
    "        ginivalue=Gini_criterion(data,f,min_node_size)\n",
    "        if ginivalue<minginivalue:\n",
    "            bestf=f\n",
    "            bestvalue=qvalue\n",
    "            minginivalue=ginivalue\n",
    "    #\n",
    "    # return the best function, the value and its gini value\n",
    "    #\n",
    "    return(bestf,bestvalue,minginivalue)  \n",
    "\n",
    "\n",
    "def find_all_set_splits(value_list):\n",
    "    splits=[]\n",
    "    n=len(value_list)\n",
    "    m=int(n/2)\n",
    "    for sz in range(1,m+1):\n",
    "        combs=it.combinations(value_list,sz)\n",
    "        for comb in combs:\n",
    "            splits.append(list(comb))\n",
    "    if 2*m<n:\n",
    "        return(splits)\n",
    "    #\n",
    "    # even case - need to add in subsets of size n/2\n",
    "    #\n",
    "    combs=it.combinations(value_list,m+1)\n",
    "    svalue_list=set(value_list) # by the way - sets can't contain mutable elements!!!\n",
    "    for comb in combs:\n",
    "        s=set(comb)\n",
    "        sc=svalue_list.difference(s)\n",
    "        if s not in splits and svalue_list.difference(s):\n",
    "            splits.append(list(s))\n",
    "    return(splits)\n",
    "    \n",
    "def find_best_splitting_function_categorical_variable(data,vname,min_node_size):\n",
    "    values=list(data[vname].unique())\n",
    "    nvalues=len(values)\n",
    "    minginivalue=data.shape[0] # Gini can't be this big\n",
    "    subset_list=find_all_set_splits(values)\n",
    "    bestf=None\n",
    "    bestsubset=None\n",
    "    for subset in subset_list:\n",
    "        def f(row):\n",
    "            if row[vname] in subset:\n",
    "                return(\"left\")\n",
    "            else:\n",
    "                return(\"right\")\n",
    "        ginivalue=Gini_criterion(data,f,min_node_size)\n",
    "        if ginivalue<minginivalue:\n",
    "            bestf=f\n",
    "            bestsubset=subset\n",
    "            minginivalue=ginivalue\n",
    "    return(bestf,bestsubset,minginivalue)  \n",
    "\n",
    "def find_best_split(data,cont_vars,cat_vars,min_node_size):\n",
    "    minginivalue=data.shape[0]\n",
    "    bestf=None\n",
    "    bestvar=None\n",
    "    bestvartype=None\n",
    "    bestvalue=None\n",
    "    for catvar in cat_vars:\n",
    "        f,b,g=find_best_splitting_function_categorical_variable(data,catvar,min_node_size)\n",
    "        if g<minginivalue:\n",
    "            minginivalue=g\n",
    "            bestvar=catvar\n",
    "            bestvartype=\"categorical\"\n",
    "            bestvalue=b\n",
    "            bestf=f\n",
    "    for contvar in cont_vars:\n",
    "        f,b,g=find_best_splitting_function_continuous_variable(data,contvar,min_node_size)\n",
    "        if g<minginivalue:\n",
    "            minginivalue=g\n",
    "            bestvar=contvar\n",
    "            bestvartype=\"continuous\"\n",
    "            bestvalue=b\n",
    "            bestf=f\n",
    "    return bestf,bestvar,bestvartype,bestvalue,minginivalue\n",
    "\n",
    "    # string consisting of information about node\n",
    "    #\n",
    "    def __str__(self):\n",
    "        s=\"node label = \"+self.data[\"label\"]+\"\\n\"\n",
    "        if self.parent==None:\n",
    "            s+=\"   no parent i.e. root node\\n\"\n",
    "        else:\n",
    "            s+=\"   parent label = \" + self.parent.data[\"label\"]+\"\\n\"\n",
    "        if self.left_child==None:\n",
    "            s+=\"   no left child\\n\"\n",
    "        else:\n",
    "            s+=\"   left child label \" + self.left_child.data[\"label\"]+\"\\n\"\n",
    "        if self.right_child==None:\n",
    "            s+=\"   no right child\\n\"\n",
    "        else:\n",
    "            s+=\"   right child label \" + self.right_child.data[\"label\"]+\"\\n\"\n",
    "        \n",
    "        return(s)\n",
    "class node:\n",
    "    __slots__=('parent','left_child','right_child','data')\n",
    "    #\n",
    "    # We instantiate a node by passing a parent (which can be None) \n",
    "    # and a dictionary\n",
    "    #\n",
    "    def __init__(self,parent,data):\n",
    "        if parent==None:\n",
    "            # making this a root node\n",
    "            self.data=data\n",
    "            self.data[\"depth\"]=0\n",
    "            self.parent=None\n",
    "        else:\n",
    "            # making this a non-root node\n",
    "            self.data=data\n",
    "            self.data[\"depth\"]=parent.data[\"depth\"]+1\n",
    "            self.parent=parent\n",
    "        self.left_child=None\n",
    "        self.right_child=None\n",
    "    def get_parent(self): # return the node's parent\n",
    "        return(self.parent)\n",
    "    def get_data(self):   # return the node's data\n",
    "        return(self.data)\n",
    "    def get_depth(self):  # return the node's depth\n",
    "        return(self.data[\"depth\"])\n",
    "    def get_label(self):\n",
    "        return(self.data[\"label\"])\n",
    "    def set_label(self,label):\n",
    "        self.data[\"label\"]=label\n",
    "    def get_left_child(self):\n",
    "        return(self.left_child)\n",
    "    def get_right_child(self):\n",
    "        return(self.right_child)\n",
    "    def spawn_left_child(self,data):\n",
    "        # create a new node n with self as parent w/ given data\n",
    "        n=node(parent=self,data=data)\n",
    "        #n.data=data\n",
    "        n.data[\"depth\"]=self.data[\"depth\"]+1\n",
    "        self.left_child=n\n",
    "        return(n)\n",
    "    def spawn_right_child(self,data):\n",
    "        n=node(parent=self,data=data)\n",
    "        n.data=data\n",
    "        n.data[\"depth\"]=self.data[\"depth\"]+1\n",
    "        self.right_child=n\n",
    "        return(n)\n",
    "    #\n",
    "    # string consisting of information about node\n",
    "    #\n",
    "    def __str__(self):\n",
    "        s=\"node label = \"+self.data[\"label\"]+\"\\n\"\n",
    "        if self.parent==None:\n",
    "            s+=\"   no parent i.e. root node\\n\"\n",
    "        else:\n",
    "            s+=\"   parent label = \" + self.parent.data[\"label\"]+\"\\n\"\n",
    "        if self.left_child==None:\n",
    "            s+=\"   no left child\\n\"\n",
    "        else:\n",
    "            s+=\"   left child label \" + self.left_child.data[\"label\"]+\"\\n\"\n",
    "        if self.right_child==None:\n",
    "            s+=\"   no right child\\n\"\n",
    "        else:\n",
    "            s+=\"   right child label \" + self.right_child.data[\"label\"]+\"\\n\"\n",
    "        return(s)\n",
    "    def treestr(self):\n",
    "        d=self.data\n",
    "        depth=d[\"depth\"]\n",
    "        G=d[\"gini\"]\n",
    "        Gstring=\"G: {:8.2f} \".format(G)\n",
    "        Y0=d[\"Ycts\"][0]\n",
    "        Y1=d[\"Ycts\"][1]\n",
    "        Ycts_string=\"N: \"+str(Y0+Y1)+\" N0: \"+str(Y0)+\" \"+\" N1:\"+str(Y1)+\"\\n\"\n",
    "        p0=Y0/(Y0+Y1)\n",
    "        p1=Y1/(Y0+Y1)\n",
    "        pstring=\"p0: {:5.4f} p1: {:5.4f}\\n\".format(p0,p1)\n",
    "        spaces=\"\".join([\"  \" for i in range(depth)])\n",
    "        s=spaces+d[\"label\"]+\"\\n\"\n",
    "        s+=spaces+Gstring+Ycts_string\n",
    "        s+=spaces+pstring\n",
    "        #\n",
    "        # if this node has a split, include info about it\n",
    "        #\n",
    "        if \"splitinfo\" in self.data:\n",
    "            splitinfo=self.data[\"splitinfo\"]\n",
    "        \n",
    "        \n",
    "        \n",
    "        if self.left_child!=None:\n",
    "            s+=self.left_child.treestr()\n",
    "            s+=self.right_child.treestr()\n",
    "        return(s)\n",
    "    def treeprint(self):\n",
    "        s=self.treestr()\n",
    "        print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recursive split node function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new node to try splitting:  size= 9864\n",
      "splitting node into sizes 6781 3083\n",
      "new node to try splitting: L size= 6781\n",
      "splitting node into sizes 2981 3800\n",
      "new node to try splitting: LL size= 2981\n",
      "splitting node into sizes 627 2354\n",
      "new node to try splitting: LLL size= 627\n",
      "node is not split since gini not reduced\n",
      "new node to try splitting: LLR size= 2354\n",
      "splitting node into sizes 637 1717\n",
      "new node to try splitting: LLRL size= 637\n",
      "node is not split since gini not reduced\n",
      "new node to try splitting: LLRR size= 1717\n",
      "node is not split because of minimum node size constraint\n",
      "new node to try splitting: LR size= 3800\n",
      "splitting node into sizes 2850 950\n",
      "new node to try splitting: LRL size= 2850\n",
      "splitting node into sizes 2133 717\n",
      "new node to try splitting: LRLL size= 2133\n",
      "splitting node into sizes 661 1472\n",
      "new node to try splitting: LRLLL size= 661\n",
      "node is not split since gini not reduced\n",
      "new node to try splitting: LRLLR size= 1472\n",
      "node is not split because of minimum node size constraint\n",
      "new node to try splitting: LRLR size= 717\n",
      "node is not split since gini not reduced\n",
      "new node to try splitting: LRR size= 950\n",
      "node is not split since gini not reduced\n",
      "new node to try splitting: R size= 3083\n",
      "splitting node into sizes 636 2447\n",
      "new node to try splitting: RL size= 636\n",
      "node is not split since gini not reduced\n",
      "new node to try splitting: RR size= 2447\n",
      "splitting node into sizes 786 1661\n",
      "new node to try splitting: RRL size= 786\n",
      "node is not split since gini not reduced\n",
      "new node to try splitting: RRR size= 1661\n",
      "splitting node into sizes 863 798\n",
      "new node to try splitting: RRRL size= 863\n",
      "node is not split since gini not reduced\n",
      "new node to try splitting: RRRR size= 798\n",
      "node is not split since gini not reduced\n"
     ]
    }
   ],
   "source": [
    "def split_node(cnode,contvars,catvars,min_node_size):  \n",
    "    cdf=cnode.data[\"df\"]\n",
    "    \n",
    "    # compute Y counts in this node and store them\n",
    "    N0=np.sum(1-cdf[\"Y\"])\n",
    "    N1=np.sum(cdf[\"Y\"])\n",
    "    cnode.data[\"Ycts\"]=[N0,N1]\n",
    "    \n",
    "    #\n",
    "    # Gini for a node is N*p(1-p) where p is prop of 1's\n",
    "    # so this equalis (N0+N1)*(N0/(N0+N1)))*(N1/(N0+N1)) = N0*N1/(N0+N1)\n",
    "    #\n",
    "    cnode.data[\"gini\"]=N0*N1/(N0+N1)\n",
    "    \n",
    "    if cnode.data[\"df\"].shape[0]>=min_node_size:\n",
    "        print(\"new node to try splitting: \"+cnode.data[\"label\"]+\" size= \"+str(cnode.data[\"df\"].shape[0]))\n",
    "        \n",
    "        # find best split\n",
    "        f,v,vtype,value,g=find_best_split(cnode.data[\"df\"],contvars,catvars,min_node_size)\n",
    "        \n",
    "        #\n",
    "        # if the split leads to a bigger gini, we don't split the node\n",
    "        # so compare to gini at current node\n",
    "        #\n",
    "        if g>=cnode.data[\"gini\"]:\n",
    "            print(\"node is not split since gini not reduced\")\n",
    "        else:\n",
    "            \n",
    "            # determine which rows of current data frame go left and which go right\n",
    "            child_assignment=cnode.data[\"df\"].apply(f,axis=1)\n",
    "        \n",
    "            # compute counts of child nodes if we split\n",
    "            nleft=np.sum(child_assignment==\"left\")\n",
    "            nright=np.sum(child_assignment==\"right\")\n",
    "            \n",
    "            if nleft<min_node_size or nright<min_node_size:\n",
    "                print(\"node is not split because of minimum node size constraint\")\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                # attach splitting function to data at this node\n",
    "                splitinfo={\"f\":f, \"vname\": v, \"vtype\":vtype, \"value\":value}\n",
    "                cnode.data[\"splitinfo\"]=splitinfo\n",
    "                     \n",
    "                print(\"splitting node into sizes \"+str(nleft)+\" \"+str(nright))\n",
    "                # compute data frames to put at child nodes\n",
    "                dfleft=cnode.data[\"df\"].loc[child_assignment==\"left\"].copy()\n",
    "                dfright=cnode.data[\"df\"].loc[child_assignment==\"right\"].copy()\n",
    "       \n",
    "                # replace data frame indices by range\n",
    "                dfleft.index=range(dfleft.shape[0])\n",
    "                dfright.index=range(dfright.shape[0])\n",
    "    \n",
    "                # create a label \n",
    "                dataleft={\"df\":dfleft,\"label\":cnode.data[\"label\"]+\"L\"}\n",
    "                dataright={\"df\":dfright,\"label\":cnode.data[\"label\"]+\"R\"}\n",
    "                        \n",
    "                # create child nodes \n",
    "                left_child=cnode.spawn_left_child(dataleft)\n",
    "                right_child=cnode.spawn_right_child(dataright)\n",
    "               \n",
    "            \n",
    "                # split child nodes\n",
    "                split_node(left_child,contvars,catvars,min_node_size)\n",
    "                split_node(right_child,contvars,catvars,min_node_size)\n",
    "\n",
    "mdata=pd.read_csv(\"mortgage_data.csv\")\n",
    "#\n",
    "# Create a Y variable - Y=1 for default Y=0 for non-default\n",
    "#\n",
    "def f(row):\n",
    "    if row[\"result\"]==\"default\":\n",
    "        return(1)\n",
    "    else:\n",
    "        return(0)\n",
    "mdata[\"Y\"]=mdata.apply(f,axis=1)\n",
    "rootnode=node(None,{\"df\":mdata,\"label\":\"\"})\n",
    "split_node(rootnode,[\"irate\",\"cscore\",\"princ\"],[\"location\"],500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "G:  2307.60 N: 9864 N0: 3682  N1:6182\n",
      "p0: 0.3733 p1: 0.6267\n",
      "  L\n",
      "  G:  1644.35 N: 6781 N0: 2803  N1:3978\n",
      "  p0: 0.4134 p1: 0.5866\n",
      "    LL\n",
      "    G:   725.20 N: 2981 N0: 1735  N1:1246\n",
      "    p0: 0.5820 p1: 0.4180\n",
      "      LLL\n",
      "      G:    38.32 N: 627 N0: 586  N1:41\n",
      "      p0: 0.9346 p1: 0.0654\n",
      "      LLR\n",
      "      G:   588.17 N: 2354 N0: 1149  N1:1205\n",
      "      p0: 0.4881 p1: 0.5119\n",
      "        LLRL\n",
      "        G:   126.02 N: 637 N0: 464  N1:173\n",
      "        p0: 0.7284 p1: 0.2716\n",
      "        LLRR\n",
      "        G:   411.72 N: 1717 N0: 685  N1:1032\n",
      "        p0: 0.3990 p1: 0.6010\n",
      "    LR\n",
      "    G:   767.84 N: 3800 N0: 1068  N1:2732\n",
      "    p0: 0.2811 p1: 0.7189\n",
      "      LRL\n",
      "      G:   648.22 N: 2850 N0: 997  N1:1853\n",
      "      p0: 0.3498 p1: 0.6502\n",
      "        LRLL\n",
      "        G:   514.59 N: 2133 N0: 867  N1:1266\n",
      "        p0: 0.4065 p1: 0.5935\n",
      "          LRLLL\n",
      "          G:   124.81 N: 661 N0: 167  N1:494\n",
      "          p0: 0.2526 p1: 0.7474\n",
      "          LRLLR\n",
      "          G:   367.12 N: 1472 N0: 700  N1:772\n",
      "          p0: 0.4755 p1: 0.5245\n",
      "        LRLR\n",
      "        G:   106.43 N: 717 N0: 130  N1:587\n",
      "        p0: 0.1813 p1: 0.8187\n",
      "      LRR\n",
      "      G:    65.69 N: 950 N0: 71  N1:879\n",
      "      p0: 0.0747 p1: 0.9253\n",
      "  R\n",
      "  G:   628.39 N: 3083 N0: 879  N1:2204\n",
      "  p0: 0.2851 p1: 0.7149\n",
      "    RL\n",
      "    G:   150.16 N: 636 N0: 243  N1:393\n",
      "    p0: 0.3821 p1: 0.6179\n",
      "    RR\n",
      "    G:   470.70 N: 2447 N0: 636  N1:1811\n",
      "    p0: 0.2599 p1: 0.7401\n",
      "      RRL\n",
      "      G:    70.26 N: 786 N0: 78  N1:708\n",
      "      p0: 0.0992 p1: 0.9008\n",
      "      RRR\n",
      "      G:   370.54 N: 1661 N0: 558  N1:1103\n",
      "      p0: 0.3359 p1: 0.6641\n",
      "        RRRL\n",
      "        G:   209.83 N: 863 N0: 360  N1:503\n",
      "        p0: 0.4171 p1: 0.5829\n",
      "        RRRR\n",
      "        G:   148.87 N: 798 N0: 198  N1:600\n",
      "        p0: 0.2481 p1: 0.7519\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rootnode.treeprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make the split node function a class method**\n",
    "\n",
    "That function has been renamed to build_tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools as it\n",
    "def Gini_criterion(df,f,min_node_size):\n",
    "    #\n",
    "    # calculate f(row) for every row in the data frame\n",
    "    # this produces a Pandas series\n",
    "    #\n",
    "    fvalue=df.apply(f,axis=1)\n",
    "    #\n",
    "    # get the series of Y's for which fvalue is \"left\" \n",
    "    # and the series of Y's for whcih fvalue is \"right\"\n",
    "    #\n",
    "    Yleft=df[\"Y\"].loc[fvalue==\"left\"]\n",
    "    Yright=df[\"Y\"].loc[fvalue==\"right\"]\n",
    "    #\n",
    "    # compute number of obs in each side\n",
    "    #\n",
    "    nleft=Yleft.size\n",
    "    nright=Yright.size\n",
    "    #\n",
    "    # if split puts too few values in a node\n",
    "    # we return a value that makes it so we'd never choose this f\n",
    "    #\n",
    "    if nleft<min_node_size or nright<min_node_size:\n",
    "        return(nleft+nright)\n",
    "    \n",
    "    p1left=Yleft.loc[Yleft==1].size/nleft\n",
    "    p1right=Yright.loc[Yright==1].size/nright\n",
    "    #\n",
    "    # compute the Gini coefficient\n",
    "    #\n",
    "    Gini=Yleft.size*p1left*(1-p1left)+Yright.size*p1right*(1-p1right)\n",
    "    return(Gini)\n",
    "def find_best_splitting_function_continuous_variable(data,vname,min_node_size):\n",
    "    qvalues=[data[vname].quantile(i/4) for i in range(1,4)]\n",
    "    minginivalue=mdata.shape[0] # Gini can't be this big\n",
    "    bestf=None\n",
    "    bestvalue=None\n",
    "    for qvalue in qvalues:\n",
    "        def f(row):\n",
    "            if row[vname]<qvalue:\n",
    "                return(\"left\")\n",
    "            else:\n",
    "                return(\"right\")\n",
    "        ginivalue=Gini_criterion(data,f,min_node_size)\n",
    "        if ginivalue<minginivalue:\n",
    "            bestf=f\n",
    "            bestvalue=qvalue\n",
    "            minginivalue=ginivalue\n",
    "    #\n",
    "    # return the best function, the value and its gini value\n",
    "    #\n",
    "    return(bestf,bestvalue,minginivalue)  \n",
    "\n",
    "\n",
    "def find_all_set_splits(value_list):\n",
    "    splits=[]\n",
    "    n=len(value_list)\n",
    "    m=int(n/2)\n",
    "    for sz in range(1,m+1):\n",
    "        combs=it.combinations(value_list,sz)\n",
    "        for comb in combs:\n",
    "            splits.append(list(comb))\n",
    "    if 2*m<n:\n",
    "        return(splits)\n",
    "    #\n",
    "    # even case - need to add in subsets of size n/2\n",
    "    #\n",
    "    combs=it.combinations(value_list,m+1)\n",
    "    svalue_list=set(value_list) # by the way - sets can't contain mutable elements!!!\n",
    "    for comb in combs:\n",
    "        s=set(comb)\n",
    "        sc=svalue_list.difference(s)\n",
    "        if s not in splits and svalue_list.difference(s):\n",
    "            splits.append(list(s))\n",
    "    return(splits)\n",
    "    \n",
    "def find_best_splitting_function_categorical_variable(data,vname,min_node_size):\n",
    "    values=list(data[vname].unique())\n",
    "    nvalues=len(values)\n",
    "    minginivalue=data.shape[0] # Gini can't be this big\n",
    "    subset_list=find_all_set_splits(values)\n",
    "    bestf=None\n",
    "    bestsubset=None\n",
    "    for subset in subset_list:\n",
    "        def f(row):\n",
    "            if row[vname] in subset:\n",
    "                return(\"left\")\n",
    "            else:\n",
    "                return(\"right\")\n",
    "        ginivalue=Gini_criterion(data,f,min_node_size)\n",
    "        if ginivalue<minginivalue:\n",
    "            bestf=f\n",
    "            bestsubset=subset\n",
    "            minginivalue=ginivalue\n",
    "    return(bestf,bestsubset,minginivalue)  \n",
    "\n",
    "def find_best_split(data,cont_vars,cat_vars,min_node_size):\n",
    "    minginivalue=data.shape[0]\n",
    "    bestf=None\n",
    "    bestvar=None\n",
    "    bestvartype=None\n",
    "    bestvalue=None\n",
    "    for catvar in cat_vars:\n",
    "        f,b,g=find_best_splitting_function_categorical_variable(data,catvar,min_node_size)\n",
    "        if g<minginivalue:\n",
    "            minginivalue=g\n",
    "            bestvar=catvar\n",
    "            bestvartype=\"categorical\"\n",
    "            bestvalue=b\n",
    "            bestf=f\n",
    "    for contvar in cont_vars:\n",
    "        f,b,g=find_best_splitting_function_continuous_variable(data,contvar,min_node_size)\n",
    "        if g<minginivalue:\n",
    "            minginivalue=g\n",
    "            bestvar=contvar\n",
    "            bestvartype=\"continuous\"\n",
    "            bestvalue=b\n",
    "            bestf=f\n",
    "    return bestf,bestvar,bestvartype,bestvalue,minginivalue\n",
    "\n",
    "class node:\n",
    "    __slots__=('parent','left_child','right_child','data')\n",
    "    #\n",
    "    # We instantiate a node by passing a parent (which can be None) \n",
    "    # and a dictionary\n",
    "    #\n",
    "    def __init__(self,parent,data):\n",
    "        if parent==None:\n",
    "            # making this a root node\n",
    "            self.data=data\n",
    "            self.data[\"depth\"]=0\n",
    "            self.parent=None\n",
    "        else:\n",
    "            # making this a non-root node\n",
    "            self.data=data\n",
    "            self.data[\"depth\"]=parent.data[\"depth\"]+1\n",
    "            self.parent=parent\n",
    "        self.left_child=None\n",
    "        self.right_child=None\n",
    "    def get_parent(self): # return the node's parent\n",
    "        return(self.parent)\n",
    "    def get_data(self):   # return the node's data\n",
    "        return(self.data)\n",
    "    def get_depth(self):  # return the node's depth\n",
    "        return(self.data[\"depth\"])\n",
    "    def get_label(self):\n",
    "        return(self.data[\"label\"])\n",
    "    def set_label(self,label):\n",
    "        self.data[\"label\"]=label\n",
    "    def get_left_child(self):\n",
    "        return(self.left_child)\n",
    "    def get_right_child(self):\n",
    "        return(self.right_child)\n",
    "    def spawn_left_child(self,data):\n",
    "        # create a new node n with self as parent w/ given data\n",
    "        n=node(parent=self,data=data)\n",
    "        #n.data=data\n",
    "        n.data[\"depth\"]=self.data[\"depth\"]+1\n",
    "        self.left_child=n\n",
    "        return(n)\n",
    "    def spawn_right_child(self,data):\n",
    "        n=node(parent=self,data=data)\n",
    "        n.data=data\n",
    "        n.data[\"depth\"]=self.data[\"depth\"]+1\n",
    "        self.right_child=n\n",
    "        return(n)\n",
    "    #\n",
    "    # string consisting of information about node\n",
    "    #\n",
    "    def __str__(self):\n",
    "        s=\"node label = \"+self.data[\"label\"]+\"\\n\"\n",
    "        if self.parent==None:\n",
    "            s+=\"   no parent i.e. root node\\n\"\n",
    "        else:\n",
    "            s+=\"   parent label = \" + self.parent.data[\"label\"]+\"\\n\"\n",
    "        if self.left_child==None:\n",
    "            s+=\"   no left child\\n\"\n",
    "        else:\n",
    "            s+=\"   left child label \" + self.left_child.data[\"label\"]+\"\\n\"\n",
    "        if self.right_child==None:\n",
    "            s+=\"   no right child\\n\"\n",
    "        else:\n",
    "            s+=\"   right child label \" + self.right_child.data[\"label\"]+\"\\n\"\n",
    "        return(s)\n",
    "    def treestr(self):\n",
    "        d=self.data\n",
    "        depth=d[\"depth\"]\n",
    "        G=d[\"gini\"]\n",
    "        Gstring=\"G: {:8.2f} \".format(G)\n",
    "        Y0=d[\"Ycts\"][0]\n",
    "        Y1=d[\"Ycts\"][1]\n",
    "        Ycts_string=\"N: \"+str(Y0+Y1)+\" N0: \"+str(Y0)+\" \"+\" N1:\"+str(Y1)+\"\\n\"\n",
    "        p0=Y0/(Y0+Y1)\n",
    "        p1=Y1/(Y0+Y1)\n",
    "        pstring=\"p0: {:5.4f} p1: {:5.4f}\\n\".format(p0,p1)\n",
    "        spaces=\"\".join([\"  \" for i in range(depth)])\n",
    "        s=spaces+d[\"label\"]+\"\\n\"\n",
    "        s+=spaces+Gstring+Ycts_string\n",
    "        s+=spaces+pstring\n",
    "        #\n",
    "        # if this node has a split, include info about it\n",
    "        #\n",
    "        if \"splitinfo\" in self.data:\n",
    "            splitinfo=self.data[\"splitinfo\"]\n",
    "        \n",
    "        \n",
    "        \n",
    "        if self.left_child!=None:\n",
    "            s+=self.left_child.treestr()\n",
    "            s+=self.right_child.treestr()\n",
    "        return(s)\n",
    "    def treeprint(self):\n",
    "        s=self.treestr()\n",
    "        print(s)\n",
    "    def build_tree(self,contvars,catvars,min_node_size):  \n",
    "        cdf=self.data[\"df\"]\n",
    "    \n",
    "        # compute Y counts in this node and store them\n",
    "        N0=np.sum(1-cdf[\"Y\"])\n",
    "        N1=np.sum(cdf[\"Y\"])\n",
    "        self.data[\"Ycts\"]=[N0,N1]\n",
    "    \n",
    "        #\n",
    "        # Gini for a node is N*p(1-p) where p is prop of 1's\n",
    "        # so this equalis (N0+N1)*(N0/(N0+N1)))*(N1/(N0+N1)) = N0*N1/(N0+N1)\n",
    "        #\n",
    "        self.data[\"gini\"]=N0*N1/(N0+N1)\n",
    "    \n",
    "        if self.data[\"df\"].shape[0]>=min_node_size:\n",
    "            print(\"new node to try splitting: \"+self.data[\"label\"]+\" size= \"+str(self.data[\"df\"].shape[0]))\n",
    "        \n",
    "            # find best split\n",
    "            f,v,vtype,value,g=find_best_split(self.data[\"df\"],contvars,catvars,min_node_size)\n",
    "        \n",
    "            #\n",
    "            # if the split leads to a bigger gini, we don't split the node\n",
    "            # so compare to gini at current node\n",
    "            #\n",
    "            if g>=self.data[\"gini\"]:\n",
    "                print(\"node is not split since gini not reduced\")\n",
    "            else:\n",
    "            \n",
    "                # determine which rows of current data frame go left and which go right\n",
    "                child_assignment=self.data[\"df\"].apply(f,axis=1)\n",
    "        \n",
    "                # compute counts of child nodes if we split\n",
    "                nleft=np.sum(child_assignment==\"left\")\n",
    "                nright=np.sum(child_assignment==\"right\")\n",
    "            \n",
    "                if nleft<min_node_size or nright<min_node_size:\n",
    "                    print(\"node is not split because of minimum node size constraint\")\n",
    "                \n",
    "                else:\n",
    "                \n",
    "                    # attach splitting function to data at this node\n",
    "                    splitinfo={\"f\":f, \"vname\": v, \"vtype\":vtype, \"value\":value}\n",
    "                    self.data[\"splitinfo\"]=splitinfo\n",
    "                     \n",
    "                    print(\"splitting node into sizes \"+str(nleft)+\" \"+str(nright))\n",
    "                    # compute data frames to put at child nodes\n",
    "                    dfleft=self.data[\"df\"].loc[child_assignment==\"left\"].copy()\n",
    "                    dfright=self.data[\"df\"].loc[child_assignment==\"right\"].copy()\n",
    "       \n",
    "                    # replace data frame indices by range\n",
    "                    dfleft.index=range(dfleft.shape[0])\n",
    "                    dfright.index=range(dfright.shape[0])\n",
    "    \n",
    "                    # create a label \n",
    "                    dataleft={\"df\":dfleft,\"label\":self.data[\"label\"]+\"L\"}\n",
    "                    dataright={\"df\":dfright,\"label\":self.data[\"label\"]+\"R\"}\n",
    "                        \n",
    "                    # create child nodes \n",
    "                    left_child=self.spawn_left_child(dataleft)\n",
    "                    right_child=self.spawn_right_child(dataright)\n",
    "               \n",
    "            \n",
    "                    # split child nodes\n",
    "                    left_child.build_tree(contvars,catvars,min_node_size)\n",
    "                    right_child.build_tree(contvars,catvars,min_node_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test the method**\n",
    "\n",
    "We create a root node, attach a data frame to it, call the build_tree method a this node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new node to try splitting:  size= 9864\n",
      "splitting node into sizes 6781 3083\n",
      "new node to try splitting: L size= 6781\n",
      "splitting node into sizes 2981 3800\n",
      "new node to try splitting: LL size= 2981\n",
      "splitting node into sizes 627 2354\n",
      "new node to try splitting: LLL size= 627\n",
      "node is not split since gini not reduced\n",
      "new node to try splitting: LLR size= 2354\n",
      "splitting node into sizes 637 1717\n",
      "new node to try splitting: LLRL size= 637\n",
      "node is not split since gini not reduced\n",
      "new node to try splitting: LLRR size= 1717\n",
      "node is not split because of minimum node size constraint\n",
      "new node to try splitting: LR size= 3800\n",
      "splitting node into sizes 2850 950\n",
      "new node to try splitting: LRL size= 2850\n",
      "splitting node into sizes 2133 717\n",
      "new node to try splitting: LRLL size= 2133\n",
      "splitting node into sizes 661 1472\n",
      "new node to try splitting: LRLLL size= 661\n",
      "node is not split since gini not reduced\n",
      "new node to try splitting: LRLLR size= 1472\n",
      "node is not split because of minimum node size constraint\n",
      "new node to try splitting: LRLR size= 717\n",
      "node is not split since gini not reduced\n",
      "new node to try splitting: LRR size= 950\n",
      "node is not split since gini not reduced\n",
      "new node to try splitting: R size= 3083\n",
      "splitting node into sizes 636 2447\n",
      "new node to try splitting: RL size= 636\n",
      "node is not split since gini not reduced\n",
      "new node to try splitting: RR size= 2447\n",
      "splitting node into sizes 786 1661\n",
      "new node to try splitting: RRL size= 786\n",
      "node is not split since gini not reduced\n",
      "new node to try splitting: RRR size= 1661\n",
      "splitting node into sizes 863 798\n",
      "new node to try splitting: RRRL size= 863\n",
      "node is not split since gini not reduced\n",
      "new node to try splitting: RRRR size= 798\n",
      "node is not split since gini not reduced\n"
     ]
    }
   ],
   "source": [
    "mdata=pd.read_csv(\"mortgage_data.csv\")\n",
    "#\n",
    "# Create a Y variable - Y=1 for default Y=0 for non-default\n",
    "#\n",
    "def f(row):\n",
    "    if row[\"result\"]==\"default\":\n",
    "        return(1)\n",
    "    else:\n",
    "        return(0)\n",
    "mdata[\"Y\"]=mdata.apply(f,axis=1)\n",
    "rootnode=node(None,{\"df\":mdata,\"label\":\"\"})\n",
    "rootnode.build_tree([\"irate\",\"cscore\",\"princ\"],[\"location\"],500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "G:  2307.60 N: 9864 N0: 3682  N1:6182\n",
      "p0: 0.3733 p1: 0.6267\n",
      "  L\n",
      "  G:  1644.35 N: 6781 N0: 2803  N1:3978\n",
      "  p0: 0.4134 p1: 0.5866\n",
      "    LL\n",
      "    G:   725.20 N: 2981 N0: 1735  N1:1246\n",
      "    p0: 0.5820 p1: 0.4180\n",
      "      LLL\n",
      "      G:    38.32 N: 627 N0: 586  N1:41\n",
      "      p0: 0.9346 p1: 0.0654\n",
      "      LLR\n",
      "      G:   588.17 N: 2354 N0: 1149  N1:1205\n",
      "      p0: 0.4881 p1: 0.5119\n",
      "        LLRL\n",
      "        G:   126.02 N: 637 N0: 464  N1:173\n",
      "        p0: 0.7284 p1: 0.2716\n",
      "        LLRR\n",
      "        G:   411.72 N: 1717 N0: 685  N1:1032\n",
      "        p0: 0.3990 p1: 0.6010\n",
      "    LR\n",
      "    G:   767.84 N: 3800 N0: 1068  N1:2732\n",
      "    p0: 0.2811 p1: 0.7189\n",
      "      LRL\n",
      "      G:   648.22 N: 2850 N0: 997  N1:1853\n",
      "      p0: 0.3498 p1: 0.6502\n",
      "        LRLL\n",
      "        G:   514.59 N: 2133 N0: 867  N1:1266\n",
      "        p0: 0.4065 p1: 0.5935\n",
      "          LRLLL\n",
      "          G:   124.81 N: 661 N0: 167  N1:494\n",
      "          p0: 0.2526 p1: 0.7474\n",
      "          LRLLR\n",
      "          G:   367.12 N: 1472 N0: 700  N1:772\n",
      "          p0: 0.4755 p1: 0.5245\n",
      "        LRLR\n",
      "        G:   106.43 N: 717 N0: 130  N1:587\n",
      "        p0: 0.1813 p1: 0.8187\n",
      "      LRR\n",
      "      G:    65.69 N: 950 N0: 71  N1:879\n",
      "      p0: 0.0747 p1: 0.9253\n",
      "  R\n",
      "  G:   628.39 N: 3083 N0: 879  N1:2204\n",
      "  p0: 0.2851 p1: 0.7149\n",
      "    RL\n",
      "    G:   150.16 N: 636 N0: 243  N1:393\n",
      "    p0: 0.3821 p1: 0.6179\n",
      "    RR\n",
      "    G:   470.70 N: 2447 N0: 636  N1:1811\n",
      "    p0: 0.2599 p1: 0.7401\n",
      "      RRL\n",
      "      G:    70.26 N: 786 N0: 78  N1:708\n",
      "      p0: 0.0992 p1: 0.9008\n",
      "      RRR\n",
      "      G:   370.54 N: 1661 N0: 558  N1:1103\n",
      "      p0: 0.3359 p1: 0.6641\n",
      "        RRRL\n",
      "        G:   209.83 N: 863 N0: 360  N1:503\n",
      "        p0: 0.4171 p1: 0.5829\n",
      "        RRRR\n",
      "        G:   148.87 N: 798 N0: 198  N1:600\n",
      "        p0: 0.2481 p1: 0.7519\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rootnode.treeprint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py313",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
